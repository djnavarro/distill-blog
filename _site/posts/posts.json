[
  {
    "path": "posts/2021-09-14_tidy-tuesday-billboard/",
    "title": "Title in sentence case",
    "description": "Neque porro quisquam est qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit",
    "author": [
      {
        "name": "Danielle Navarro",
        "url": "https://djnavarro.net"
      }
    ],
    "date": "2021-09-14",
    "categories": [],
    "contents": "\n\n\n\nI’ve never participated in Tidy Tuesday before, but because I’ve now joined a slack that does, it is high time I did something about that poor track record. I wasn’t sure what I wanted to do with this week’s “Billboard” data, other than I wanted it to have something to do with Britney Spears (because she’s awesome). After going back and forward for a while, I decided what I’d do is put together a couple of plots showing the chart performance of all her songs and – more importantly – write it up as a blog post in which I try to “over-explain” all my choices. There are a lot of people in our slack who haven’t used R very much, and I want to “unpack” some of the bits and pieces that are involved. This post is pitched at beginners who are hoping for a little bit of extra scaffolding to explain some of the processes…\nFinding the data on GitHub\nEvery week the Tidy Tuesday data are posted online, and the first step in participating is generally to import the data. After a little bit of hunting online, you might discover that the link to the billboard data looks like this:\nhttps://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-14/billboard.csv\nLet’s start by unpacking this link. There is a lot of assumed knowledge buried here, and while it is entirely possible for you to get started without understanding it all, for most of us in the slack group the goal is to learn new data science skills. At some point you are probably going to want to learn the “version control” magic. This post is not the place to learn this sorcery, but I am going to start foreshadowing some important concepts because they will be useful later.\nGitHub repositories\nThe place to start in understanding this link is the peculiar bit at the beginning: what is this “github” nonsense? The long answer is very long, but the short answer is that https://github.com is a website that programmers use to store their code. GitHub is one of several sites (e.g., https://gitlab.org, https://bitbucket.com) that built on top of a system called “git”. Git is a powerful tool that lets you collaborate with other people when writing code, allows you to keep track of the history of your code, and to backup your code online in case your laptop mysteriously catches on fire. It takes quite some time to get the hang of (I’m still learning, quite frankly), but it is worth your effort. When you have time, I recommend starting a free GitHub account. You can sign up using an email address, and if you have a university email address you get the educational discount (basically you get the “pro” version for free). My username on GitHub is djnavarro, and you can find my profile page here:\nhttps://github.com/djnavarro\nThe Tidy Tuesday project originated in the “R for data science” learning community (R for data science is a wonderful free resource written by Hadley Wickham and Garrett Grolemund), and there is a profile page for that community too:\nhttps://github.com/rfordatascience\nOkay, so that’s part of the link explained. The next thing to understand is that when you create projects using git and post them to GitHub, they are organised in a “repository” (“repo” for short). Each repo has its own page. The Tidy Tuesday repo is here:\nhttps://github.com/rfordatascience/tidytuesday\nIf you click on this link, you’ll find that there’s a nice description of the whole project, links to data sets, and a whole lot of other things besides. Most of the work organising this is done by Thomas Mock.\nRepositories have branches\nWhenever someone creates a git repository, it will automatically have at least one “branch” (usually called “master” or “main”). The idea behind it is really sensible: suppose you’re working on a project and you think “ooooh, I have a cool idea I want to try but maybe it won’t work”. What you can do is create a new “branch” and try out all your new ideas in the new branch all without ever affecting the master branch. It’s a safe way to explore: if your new idea works you can “merge” the changes into the master branch, but if it fails you can switch back to the master branch and pick up where you left off. No harm done. If you have lots of branches, you effectively have a “tree”, and it’s a suuuuuuper handy feature. Later on as you develop your data science skills you’ll learn how to do this yourself, but for now this is enough information. The key thing is that what you’re looking at when you visit the Tidy Tuesday page on GitHub is actually the master branch on the tree:\nhttps://github.com/rfordatascience/tidytuesday/tree/master\nRepositories are usually organised\nThe Tidy Tuesday repository has a lot of different content, and it’s all nicely organised into folders (no different to the folders you’d have on your own computer). One of the folders is called “data”, and inside the “data” folder there is a “2021” folder:\nhttps://github.com/rfordatascience/tidytuesday/tree/master/data/2021\nInside that folder you find lots more folders, one for every week this year. If you scroll down to the current week and click on the link, it will take you here:\nhttps://github.com/rfordatascience/tidytuesday/tree/master/data/2021/2021-09-14\nBeing the kind soul that he is, Thomas has included a “readme” file (that’s the nice human readable thing that gets displayed) underneath. Whenever you’re doing a Tidy Tuesday analysis, it’s super helpful to look at the readme file, because it will provide you a lot of the context you need to understand the data. Whenever doing your own projects, I’d strongly recommend creating readme files yourself: they’re really helpful to anyone using your work, even if that’s just you several months later after you’ve forgotten what you were doing.\nIn any case, one of the things you’ll see on that page is a link to the “billboard.csv” data. If you click on that link it will take you here:\nhttps://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-09-14/billboard.csv\nNotice that this doesn’t take you to the data file itself: it goes to a webpage! Specifically, it takes you to the “blob” link that displays some information about the file (notice the “blob” that has sneakily inserted itself into the link above?). In this case, the page won’t show you very much information at all because the csv file is 43.7MB in size and GitHub doesn’t try to display files that big! However, what it does give you is a link that tells you where they’ve hidden the raw file! If you click on it (which I don’t recommend), it will take you to the “raw” file located at…\nhttps://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-14/billboard.csv\nThis is the link that you might have discovered if you’d been googling to find the Billboard data. It’s a GitHub link, but GitHub uses the “raw.githubusercontent.com” site as the mechanism for making raw files accessible, which is why that part of the link has changed.\nThe anatomy of the data link\nAll of this tedious exposition should (I hope) help you make sense of what you’re actually looking at when you see this link. In real life I would never bother to do this, but if you wanted to you could decompose the link into its parts. In the snippet below I’ll create separate variables in R, one for each component of the link:\n\n\nsite <- \"https://raw.githubusercontent.com\"\nuser <- \"rfordatascience\"\nrepo <- \"tidytuesday\"\nfolder1 <- \"data\"\nfolder2 <- \"2021\" \nfolder3 <- \"2021-09-14\"\nfile <- \"billboard.csv\"\n\n\n\nOne thing you might be wondering, when you look at this snippet, is where that pretty “arrow” character comes from. Don’t be fooled. It’s actually two characters. What I’ve actually typed is <-, but this blog uses a fancy pants font that contains a special ligature that joins the two characters together. The font is called “Fira Code”, and a lot of programmers use it on their blogs. Once you know the trick, it’s really nice because it does make the code a little easier to read, but it can be confusing if you’re completely new to programming! It’s one of those little things that people forget to tell you about :-)\nAnyway, getting back on topic. The URL (“uniform resource locator”, a.k.a. “link”) for the Billboard data file is what you get when you paste all these components together, separated by the / character:\n\n\ndata_url <- paste(\n  site, \n  user, \n  repo,           \n  folder1, \n  folder2, \n  folder3, \n  file, \n  sep = \"/\"\n)\n\ndata_url\n\n\n[1] \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/data/2021/2021-09-14/billboard.csv\"\n\nExciting stuff.\nPackages\nPackages I’m going to use a lot get attached:\n\n\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\n\n\n\nImport the data\nSo I can read the data with the following code1\n\n\nbillboard <- readr::read_csv(params$data)\nbillboard\n\n\n# A tibble: 327,895 × 10\n   url      week_id  week_position song   performer song_id   instance\n   <chr>    <chr>            <dbl> <chr>  <chr>     <chr>        <dbl>\n 1 http://… 7/17/19…            34 Don't… Patty Du… Don't Ju…        1\n 2 http://… 7/24/19…            22 Don't… Patty Du… Don't Ju…        1\n 3 http://… 7/31/19…            14 Don't… Patty Du… Don't Ju…        1\n 4 http://… 8/7/1965            10 Don't… Patty Du… Don't Ju…        1\n 5 http://… 8/14/19…             8 Don't… Patty Du… Don't Ju…        1\n 6 http://… 8/21/19…             8 Don't… Patty Du… Don't Ju…        1\n 7 http://… 8/28/19…            14 Don't… Patty Du… Don't Ju…        1\n 8 http://… 9/4/1965            36 Don't… Patty Du… Don't Ju…        1\n 9 http://… 4/19/19…            97 Don't… Teddy Pe… Don't Ke…        1\n10 http://… 4/26/19…            90 Don't… Teddy Pe… Don't Ke…        1\n# … with 327,885 more rows, and 3 more variables:\n#   previous_week_position <dbl>, peak_position <dbl>,\n#   weeks_on_chart <dbl>\n\nAssembling the Britney data\nMake a decision: today I have love only for Britney. First up, let’s take a quick look at the performer variable, because I suspect she’s going to appear in a few different forms:\n\n\nbillboard %>% \n  pull(performer) %>% \n  str_subset(\"(Britney)|(Spears)\") %>% \n  table() %>% \n  sort(decreasing = TRUE)\n\n\n.\n                              Britney Spears \n                                         413 \n            Rihanna Featuring Britney Spears \n                                          26 \nBritney Spears Featuring Nicki Minaj & Ke$ha \n                                          24 \n                  will.i.am & Britney Spears \n                                          24 \n            Britney Spears Featuring Madonna \n                                          13 \n                            Billie Jo Spears \n                                           9 \n             Britney Spears Featuring G-Eazy \n                                           9 \n                Britney Spears & Iggy Azalea \n                                           8 \n            Britney Spears Featuring Tinashe \n                                           1 \n\nAnother decision: I’m happy to include her collaborations with other artists, but I only want cases where she is the primary artist. So the regular expression I’m going to use to select Britney songs is \"^Britney Spears\". That matches the following:\n\n\nbillboard %>% \n  pull(performer) %>% \n  str_subset(\"^Britney Spears\") %>% \n  unique()\n\n\n[1] \"Britney Spears\"                              \n[2] \"Britney Spears & Iggy Azalea\"                \n[3] \"Britney Spears Featuring G-Eazy\"             \n[4] \"Britney Spears Featuring Madonna\"            \n[5] \"Britney Spears Featuring Tinashe\"            \n[6] \"Britney Spears Featuring Nicki Minaj & Ke$ha\"\n\nIt retains Britney songs featuring other artists but not songs by other artists featuring Britney. Filter:\n\n\nbritney <- billboard %>% \n  filter(str_detect(performer, \"^Britney Spears\")) %>% \n  mutate(date = lubridate::mdy(week_id))\n\n\n\nA quick glimpse():\n\n\nglimpse(britney)\n\n\nRows: 468\nColumns: 11\n$ url                    <chr> \"http://www.billboard.com/charts/hot-…\n$ week_id                <chr> \"4/22/2000\", \"10/24/2009\", \"12/20/200…\n$ week_position          <dbl> 67, 1, 3, 70, 70, 21, 17, 29, 76, 1, …\n$ song                   <chr> \"Oops!...I Did It Again\", \"3\", \"Circu…\n$ performer              <chr> \"Britney Spears\", \"Britney Spears\", \"…\n$ song_id                <chr> \"Oops!...I Did It AgainBritney Spears…\n$ instance               <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ previous_week_position <dbl> NA, NA, NA, NA, NA, 45, NA, NA, NA, N…\n$ peak_position          <dbl> 67, 1, 3, 70, 70, 21, 17, 29, 76, 1, …\n$ weeks_on_chart         <dbl> 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 8, 1, 1…\n$ date                   <date> 2000-04-22, 2009-10-24, 2008-12-20, …\n\nVisualise\n\n\nhighlights <- c(\"Work B**ch!\", \"...Baby One More Time\", \"Toxic\")\n\npic <- britney %>% \n  ggplot(aes(\n    x = date, \n    y = week_position, \n    group = song\n  )) + \n  geom_line() + \n  geom_point() + \n  scale_y_reverse() + \n  gghighlight::gghighlight(song %in% highlights)\n\npic\n\n\n\n\n\n\npic <- britney %>% \n  ggplot(aes(\n    x = weeks_on_chart, \n    y = week_position, \n    group = song,\n    colour = song\n  )) + \n  geom_line() + \n  geom_point() + \n  scale_y_reverse() + \n  gghighlight::gghighlight(\n    song %in% highlights\n  )\n\npic\n\n\n\n\n\n\n\n\n\n\n\n\n\nI also set cache=TRUE in the chunk options to avoid downloading the data each time I knit the post, and added the cached folder to the .gitignore file to avoid placing cached data under version control↩︎\n",
    "preview": "posts/2021-09-14_tidy-tuesday-billboard/index_files/figure-html5/britney-chart-positions-1-1.png",
    "last_modified": "2021-09-16T12:47:07+10:00",
    "input_file": "index.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-09-07_water-colours/",
    "title": "Art, jasmines, and the water colours",
    "description": "An essay and tutorial covering a few useful art techniques in R",
    "author": [
      {
        "name": "Danielle Navarro",
        "url": "https://djnavarro.net"
      }
    ],
    "date": "2021-09-07",
    "categories": [],
    "contents": "\n\nContents\nPrelude\nThe water colours repository\nWhy use version control here?\nThe manifest file\nPreviewing the artwork\n\nDependencies\nArt from image processing\nFinding the image file\nImporting the image\nConverting the image to data\nArt from data visualisation\nExtracting the colour channels\nArt from channel manipulation\n\nIntermission\nArt from noise generators\nMultidimensional noise generation\nArt from the noise\nAccumulating art with purrr\n\nAssembling the parts\nAdding noise to jasmines coordinates\nJoining the noise with jasmine colours\nThe last chapter\n\nEpilogue\n\n\n\nPrelude\nIn recent weeks I’ve been posting generative art from the Water Colours series on twitter. The series has been popular, prompting requests that I sell prints, mint NFTs, or write a tutorial showing how they are made. For personal reasons I didn’t want to commercialise this series. Instead, I chose to make the pieces freely available under a CC0 public domain licence and asked people to donate to a gofundme I set up for a charitable organisation I care about (the Lou’s Place women’s refuge here in Sydney). I’m not going to discuss the personal story behind this series, but it does matter. As I’ve mentioned previously, the art I make is inherently tied to moods. It is emotional in nature. In hindsight it is easy enough to describe how the system is implemented but this perspective is misleading. Although a clean and unemotional description of the code is useful for explanatory purposes, the actual process of creating the system is deeply tied to my life, my history, and my subjective experience. Those details are inextricably bound to the system. A friend described it better than I ever could:\n\nThe computer doesn’t make this art any more than a camera makes a photograph; art is always intimate (Amy Patterson)\n\nIn this post I’ll describe the mechanistic processes involved in creating these pieces, but this is woefully inadequate as a description of the artistic process as a whole. The optical mechanics of a camera do not circumscribe the work of a skilled photographer. So it goes with generative art. The code describes the mechanics; it does not describe the art. There is a deeply personal story underneath these pieces (one that I won’t tell here), and I would no more mint an NFT from that story than I would sell a piece of my soul to a collector.\nThe water colours repository\nWhy use version control here?\nWhen I started making generative art I didn’t think much about archiving my art or keeping it organised. I liked making pretty things, and that was as far as my thought process went. I didn’t place the code under version control, and I stored everything in my Dropbox folder. There’s nothing wrong with that: some things don’t belong on GitHub. During the development phase of any art project that’s still what I do, and I’m perfectly happy with it.\nThings become a little trickier when you want to share the art. My art website is hosted on GitHub pages, and so my initial approach was to keep the art in the website repository. Huuuuge mistake. Sometimes the image files can be quite large and sometimes a series contains a large number of images. By the time I’d reached 40+ series, Hugo took a very long time to build the site (several minutes), and GitHub took even longer to deploy it (over half an hour).\nEventually I decided it made more sense to have one repository per series. Each one uses the “series-” prefix to remind me it’s an art repo. I don’t use these repositories during development: they exist solely to snapshot the release. For example, the series-water-colours repository isn’t going to be updated regularly, it’s really just an archive combined with a “docs” folder that is used to host a minimal GitHub Pages site that makes the images public. It’s convenient for my purposes because my art website doesn’t have to host any of the images: all it does is hotlink to the images that are exposed via the series repo.\nIt may seem surprising that I’ve used GitHub for this. Image files aren’t exactly well suited to version control, but it’s not like they’re going to be updated. Plus, there are a lot of advantages. I can explicitly include licencing information in the repository, I can release source code (when I want to), and I can include a readme file for anyone who wants to use it.\nThe manifest file\nOne nice feature of doing things this way is that it has encouraged me to include a manifest file. Because the image files belong to a completely different repository to the website, I need a way to automatically inspect the image repository and construct the links I need (because I’m waaaaaay too lazy to add the links by hand). That’s the primary function of the manifest. The manifest.csv file is a plain csv file with one row per image, and one column for each piece of metadata I want to retain about the images. It might seem like organisational overkill to be this precise about the art, but I’m starting to realise that if I don’t have a proper system in place I’ll forget minor details like “what the piece is called” or “when I made it”. That seems bad :-)\n\n\n\nI can use readr::read_csv() to download the manifest and do a little data wrangling to organise it into a format that is handy to me right now:\n\nThe data wrangling code is here\n\n\nmanifest\n\n\n# A tibble: 20 × 9\n   series      sys_id img_id short_name  format long_name   date      \n   <chr>       <chr>  <chr>  <chr>       <chr>  <chr>       <date>    \n 1 watercolour sys02  img34  teacup-oce… jpg    Ocean in a… 2021-07-31\n 2 watercolour sys02  img31  incursions  jpg    Incursions  2021-08-14\n 3 watercolour sys02  img32  percolate   jpg    Percolate   2021-08-21\n 4 watercolour sys02  img37  gentle-des… jpg    Gentle Des… 2021-08-21\n 5 watercolour sys02  img41  stormy-seas jpg    Stormy Seas 2021-08-22\n 6 watercolour sys02  img42  turmeric    jpg    Turmeric A… 2021-08-24\n 7 watercolour sys02  img43  torn-and-f… jpg    Torn and F… 2021-08-24\n 8 watercolour sys02  img47  inferno     jpg    Seventh Ci… 2021-08-27\n 9 watercolour sys02  img48  storm-cell  jpg    Storm Cell… 2021-08-27\n10 watercolour sys02  img49  tonal-earth jpg    Tonal Earth 2021-08-29\n11 watercolour sys02  img50  cold-front  jpg    Cold Front  2021-08-29\n12 watercolour sys02  img51  kintsugi-d… jpg    Kintsugi D… 2021-08-29\n13 watercolour sys02  img53  departure   jpg    Departure   2021-08-29\n14 watercolour sys02  img54  echo        jpg    Echo        2021-08-30\n15 watercolour sys02  img57  portal      jpg    Portal      2021-08-31\n16 watercolour sys02  img60  salt-stone… jpg    Gods of Sa… 2021-08-31\n17 watercolour sys02  img61  amanecer-d… jpg    El Último … 2021-09-01\n18 watercolour sys02  img65  plume       jpg    Plume       2021-09-02\n19 watercolour sys02  img67  woodland-s… jpg    Woodland S… 2021-09-02\n20 watercolour sys02  img68  below-the-… jpg    Below the … 2021-09-03\n# … with 2 more variables: path_2000 <chr>, path_500 <chr>\n\nPreviewing the artwork\nMore to the point, the manifest data frame is nicely suited for use with the bs4cards package, so I can display some of the pieces in a neat and tidy thumbnail grid. Here are the first eight pieces from the series, arranged by date of creation:\n\n\nmanifest[1:8, ] %>% \n  bs4cards::cards(\n    image = path_500,\n    link = path_2000,\n    title = long_name,\n    spacing = 3,\n    width = 2\n  )  \n\n\n\n\n\n\n\n\n\nOcean in a Teacup\n\n\n\n\n\n\n\n\nIncursions\n\n\n\n\n\n\n\n\nPercolate\n\n\n\n\n\n\n\n\nGentle Descent\n\n\n\n\n\n\n\n\nStormy Seas\n\n\n\n\n\n\n\n\nTurmeric Against Grey Tuesday\n\n\n\n\n\n\n\n\nTorn and Frayed\n\n\n\n\n\n\n\n\nSeventh Circle\n\n\n\n\n\n\nEach thumbnail image links to a medium resolution (2000 x 2000 pixels) jpg version of the corresponding piece, if you’d like to see the images in a little more detail.\nDependencies\nIn the remainder of this post I’ll walk you through the process of creating pieces “in the style of” the water colours series. If you really want to, you can take a look at the actual source, but it may not be very helpful: the code is little opaque, poorly structured, and delegates a lot of the work to the halftoner and jasmines packages, neither of which is on CRAN. To make it a little easier on you, I’ll build a new system in this post that adopts the same core ideas.\nIn this post I’ll assume you’re already familiar with data wrangling and visualisation with tidyverse tools. This is the subset of tidyverse packages that I have attached, and the code that follows relies on all these in some fashion:\n\n\nlibrary(magrittr)\nlibrary(readr)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(purrr)\nlibrary(dplyr)\n\n\n\n\nThe R environment is specified formally in the lockfile. It’s a story for another day, but for reproducibility purposes I have a separate renv configuration for every post\nIn addition to tidyverse and base R functions, I’ll use a few other packages as well. The magick, raster, rprojroot, fs, and ambient packages are all used in making the art. Because functions from those packages may not be as familiar to everyone, I’ll namespace the calls to them in the same way I did with bs4cards::cards() previously. Hopefully that will make it easier to see which functions belong to one of those packages.\nArt from image processing\nFinding the image file\nAs in life, the place to start is knowing where you are.\nThis post is part of my blog, and I’ll need to make use of an image file called \"jasmine.jpg\" stored alongside my R markdown. First, I can use rprojroot to find out where my blog is stored. I’ll do that by searching for a \"_site.yml\" file:\n\n\nblog <- rprojroot::find_root(\"_site.yml\")\nblog\n\n\n[1] \"/home/danielle/GitHub/sites/distill-blog\"\n\nI suspect that most people reading this would be more familiar with the here package that provides a simplified interface to rprojroot and will automatically detect the .Rproj or .here file associated with your project. In fact, because the here::here() function is so convenient, it’s usually my preferred method for solving this problem. Sometimes, however, the additional flexibility provided by rprojroot is very useful. Some of my projects are comprised of partially independent sub-projects, each with a distinct root directory. That happens sometimes when blogging: there are contexts in which you might want to consider “the blog” to be the project, but other contexts in which “the post” might be the project. If you’re not careful this can lead to chaos (e.g., RStudio projects nested inside other RStudio projects), and I’ve found rprojroot very helpful in avoiding ambiguity in these situations.\nHaving chosen “the blog” as the root folder, the next step in orientation is to find the post folder. Because this is a distill blog, all my posts are stored in the _posts folder, and I’ve adopted a consistent naming convention for organising the post folders. Every name begins with the post date in year-month-day format, followed by a human-readable “slug”:\n\n\npost <- paste(params$date, params$slug, sep = \"_\")\npost\n\n\n[1] \"2021-09-07_water-colours\"\n\nThis allows me to construct the path to the image file and display it here:\n\n\nfile <- fs::path(blog, \"_posts\", post, \"jasmine.jpg\")\nknitr::include_graphics(file)\n\n\n\n\n\nThe photo has an emotional resonance to me: it dates back to 2011 and appeared on the cover of Learning Statistics with R. Although 10 years separate the Water Colours series from the text and the photo, the two are linked by a shared connection to events from a decade ago\nImporting the image\nOur next step is to import the image into R at a suitable resolution. The original image size is 1000x600 pixels, which is a little more than we need. Here’s a simple import_image() function that does this:\n\n\nimport_image <- function(path, width, height) {\n  geometry <- paste0(width, \"x\", height) # e.g., \"100x60\"\n  path %>% \n    magick::image_read() %>% \n    magick::image_scale(geometry)\n}\n\n\n\nInternally, the work is being done by the fabulous magick package that provides bindings to the ImageMagick library. In truth, it’s the ImageMagick library that is doing most the work here. R doesn’t load the complete image, it lets ImageMagick take care of that. Generally that’s a good thing for performance reasons (you don’t want to load large images into memory if you can avoid it), but in this case we’re going to work with the raw image data inside R.\nThis brings us to the next task…\nConverting the image to data\nConverting the image into a data structure we can use is a two step process. First, we create a matrix that represents the image in a format similar to the image itself. That’s the job of the construct_matrix() function below. It takes the image as input, and first coerces it to a raster object and then to a regular matrix: in the code below, the matrix is named mat, and the pixel on the i-th row and j-th column of the image is represented by the contents of mat[i, j].\n\n\nconstruct_matrix <- function(image) {\n  \n  # read matrix\n  mat <- image %>% \n    as.raster() %>%\n    as.matrix()\n  \n  # use the row and column names to represent co-ordinates\n  rownames(mat) <- paste0(\"y\", nrow(mat):1) # <- flip y\n  colnames(mat) <- paste0(\"x\", 1:ncol(mat))\n  \n  return(mat)\n}\n\n\n\nA little care is needed when interpreting the rows of this matrix. When we think about graphs, the values on y-axis increase as we move our eyes upwards from the bottom, so our mental model has the small numbers at the bottom and the big numbers at the top. But that’s not the only mental model in play here. When we read a matrix or a table we don’t look at it, we read it - and we read from top to bottom. A numbered list, for example, has the smallest numbers at the top, and the numbers get bigger as we read down the list. Both of those mental models are sensible, but it’s hard to switch between them.\nThe tricky part here is that the raw image is encoded in “reading format”. It’s supposed to be read like a table or a list, so the indices increase as we read down the image. The image data returned by construct_matrix() is organised this format. However, when we draw pictures with ggplot2 later on, we’re going to need to switch to a “graph format” convention with the small numbers at the bottom. That’s the reason why the code above flips the order of the row names. Our next task will be to convert this (reading-formatted) matrix into a tidy tibble, and those row and column names will become become our (graph-formatted) x- and y-coordinates, so the row names need to be labelled in reverse order.\nTo transform the image matrix into a tidy tibble, I’ve written a handy construct_tibble() function:\n\n\nconstruct_tibble <- function(mat) {\n  \n  # convert to tibble\n  tbl <- mat %>%\n    as.data.frame() %>%\n    rownames_to_column(\"y\") %>%\n    as_tibble() \n  \n  # reshape\n  tbl <- tbl %>%\n    pivot_longer(\n      cols = starts_with(\"x\"),\n      names_to = \"x\",\n      values_to = \"shade\"\n    ) \n  \n  # tidy\n  tbl <- tbl %>%\n    arrange(x, y) %>% \n    mutate(\n      x = x %>% str_remove_all(\"x\") %>% as.numeric(),\n      y = y %>% str_remove_all(\"y\") %>% as.numeric(),\n      id = row_number()\n    )\n  \n  return(tbl)\n}\n\n\n\nThe code has the following strucure:\nThe first part of this code coerces the matrix to a plain data frame, then uses rownames_to_columns() to extract the row names before coercing it to a tibble. This step is necessary because tibbles don’t have row names, and we need those row names: our end goal is to have a variable y to store those co-ordinate values.\nThe second part of the code uses pivot_longer() to capture all the other variables (currently named x1, x2, etc) and pull them down into a single column that specifies the x co-ordinate. At this stage, the tbl tibble contains three variables: an x value, a y value, and a shade that contains the hex code for a colour.\nThe last step is to tidy up the values. After pivot_longer() does its job, the x variable contains strings like \"x1\", \"x2\", etc, but we’d prefer them to be actual numbers like 1, 2, etc. The same is true for the y variable. To fix this, the last part of the code does a tiny bit of string manipulation using str_remove_all() to get rid of the unwanted prefixes, and then coerces the result to a number.\n\nThe names_prefix argument to pivot_longer() can transform x without the third step, but I prefer the verbose form. I find it easier to read and it treats x and y the same\nTaken together, the import_image(), construct_matrix(), and construct_tibble() functions provide us with everything we need to pull the data from the image file and wrangle it into a format that ggplot2 is expecting:\n\n\njas <- file %>% \n  import_image(width = 100, height = 60) %>% \n  construct_matrix() %>% \n  construct_tibble()\n\njas\n\n\n# A tibble: 6,000 × 4\n       y     x shade        id\n   <dbl> <dbl> <chr>     <int>\n 1     1     1 #838c70ff     1\n 2    10     1 #3c3123ff     2\n 3    11     1 #503d3dff     3\n 4    12     1 #363126ff     4\n 5    13     1 #443a30ff     5\n 6    14     1 #8a6860ff     6\n 7    15     1 #665859ff     7\n 8    16     1 #5a5d51ff     8\n 9    17     1 #535c4cff     9\n10    18     1 #944b61ff    10\n# … with 5,990 more rows\n\nA little unusually, the hex codes here are specified in RGBA format: the first two alphanumeric characters specify the hexadecimal code for the red level, the second two represent the green level (or “channel”), the third two are the blue channel, and the last two are the opacity level (the alpha channel). I’m going to ignore the alpha channel for this exercise though.\nThere’s one last thing to point out before turning to the fun art part. Notice that jas also contains an id column (added by the third part of the construct_tibble() function). It’s generally good practice to have an id column that uniquely identifies each row, and will turn out to be useful later when we need to join this data set with other data sets that we’ll generate.\nArt from data visualisation\nLet the art begin!\nThe first step is to define a helper function ggplot_themed() that provides a template that we’ll reuse in every plot. Mostly this involves preventing ggplot2 from doing things it wants to do. When we’re doing data visualisation it’s great that ggplot2 automatically provides things like “legends”, “axes”, and “scales” to map from data to visual aesthetics, but from an artistic perspective they’re just clutter. I don’t want to manually strip that out every time I make a plot, so it makes sense to have a function that gets rid of all those things:\n\n\nggplot_themed <- function(data) {\n  data %>% \n    ggplot(aes(x, y)) +\n    coord_equal() + \n    scale_size_identity() + \n    scale_colour_identity() + \n    scale_fill_identity() + \n    theme_void() \n}\n\n\n\nThis “template function” allows us to start with a clean slate, and it makes our subsequent coding task easier. The x and y aesthetics are already specified, ggplot2 won’t try to “interpret” our colours and sizes for us, and it won’t mess with the aspect ratio. In a sense, this function turns off the autopilot: we’re flying this thing manually…\nThere are many ways to plot the jas data in ggplot2. The least imaginative possibility is geom_tile(), which produces a pixellated version of the jasmines photo:\n\n\njas %>% \n  ggplot_themed() + \n  geom_tile(aes(fill = shade)) \n\n\n\n\nOf course, if you are like me you always forget to use the fill aesthetic. The muscle memory tells me to use the colour aesthetic, so I often end up drawing something where only the borders of the tiles are coloured:\n\n\njas %>% \n  ggplot_themed() + \n  geom_tile(aes(colour = shade)) \n\n\n\n\nIt’s surprisingly pretty, and a cute demonstration of how good the visual system is at reconstructing images from low-quality input: remarkably, the jasmines are still perceptible despite the fact that most of the plot area is black. I didn’t end up pursuing this (yet!) but I think there’s a lot of artistic potential here. It might be worth playing with at a later date. In that sense generative art is a lot like any other kind of art (or, for that matter, science). It is as much about exploration and discovery as it is about technical prowess.\nThe path I did follow is based on geom_point(). Each pixel in the original image is plotted as a circular marker in the appropriate colour. Here’s the simplest version of this idea applied to the jas data:\n\n\njas %>% \n  ggplot_themed() + \n  geom_point(aes(colour = shade)) \n\n\n\n\nIt’s simple, but I like it.\nExtracting the colour channels\nUp to this point we haven’t been manipulating the colours in any of the plots: the hex code in the shade variable is left intact. There’s no inherent reason we should limit ourselves to such boring visualisations. All we need to do is extract the different “colour channels” and start playing around.\nIt’s not too difficult to do this: base R provides the col2rgb() function that separates the hex code into red, green, blue channels, and represents each channel with integers between 0 and 255. It also provides the rgb2hsv() function that converts this RGB format into hue, saturation, and value format, represented as numeric values between 0 and 1.\nThis technique is illustrated by the extract_channels() helper function shown below. It looks at the shade column in the data frame, and adds six new columns, one for each channel. I’m a sucker for variable names that are all the same length (often unwisely), and I’ve named them red, grn, blu, hue, sat, and val:\n\n\nextract_channels <- function(tbl) {\n  rgb <- with(tbl, col2rgb(shade))\n  hsv <- rgb2hsv(rgb)\n  tbl <- tbl %>% \n    mutate(\n      red = rgb[1, ],\n      grn = rgb[2, ],\n      blu = rgb[3, ],\n      hue = hsv[1, ],\n      sat = hsv[2, ],\n      val = hsv[3, ]\n    )\n  return(tbl)\n}\n\n\n\nHere’s what that looks like applied to the jas data:\n\n\njas <- extract_channels(jas)\njas\n\n\n# A tibble: 6,000 × 10\n       y     x shade        id   red   grn   blu    hue   sat   val\n   <dbl> <dbl> <chr>     <int> <int> <int> <int>  <dbl> <dbl> <dbl>\n 1     1     1 #838c70ff     1   131   140   112 0.220  0.200 0.549\n 2    10     1 #3c3123ff     2    60    49    35 0.0933 0.417 0.235\n 3    11     1 #503d3dff     3    80    61    61 0      0.237 0.314\n 4    12     1 #363126ff     4    54    49    38 0.115  0.296 0.212\n 5    13     1 #443a30ff     5    68    58    48 0.0833 0.294 0.267\n 6    14     1 #8a6860ff     6   138   104    96 0.0317 0.304 0.541\n 7    15     1 #665859ff     7   102    88    89 0.988  0.137 0.4  \n 8    16     1 #5a5d51ff     8    90    93    81 0.208  0.129 0.365\n 9    17     1 #535c4cff     9    83    92    76 0.260  0.174 0.361\n10    18     1 #944b61ff    10   148    75    97 0.950  0.493 0.580\n# … with 5,990 more rows\n\nA whole new world of artistic possibilities has just emerged!\nArt from channel manipulation\nOne way to use this representation is in halftone images. If you have a printer that contains only black ink, you can approximate shades of grey by using the size of each dot to represent how dark that pixel should be:\n\n\nmap_size <- function(x) {\n  ambient::normalise(1-x, to = c(0, 2))\n}\n\njas %>% \n  ggplot_themed() +  \n  geom_point(\n    mapping = aes(size = map_size(val)),\n    colour = \"black\", \n    show.legend = FALSE\n  )\n\n\n\n\n\nIn this code the ambient::normalise() function is used to rescale the input to fall within a specified range. Usually ggplot2 handles this automatically, but as I mentioned, we’ve turned off the autopilot…\nFor real world printers, this approach is very convenient because it allows us to construct any shade we like using only a few different colours of ink. In the halftone world shades of grey are merely blacks of different size, pinks are merely sizes of red (sort of), and so on.\nBut we’re not using real printers, and in any case the image above is not a very good example of a halftone format: I’m crudely mapping 1-val to the size aesthetic, and that’s not actually the right way to do this (if you want to see this done properly, look at the halftoner package). The image above is “inspired by” the halftone concept, not the real thing. I’m okay with that, and abandoning the idea of fidelity opens up new possibilities. For example, there’s nothing stopping us retaining the original hue and saturation, while using dot size to represent the intensity value. That allows us to produce “halftonesque” images like this:\n\n\njas %>% \n  ggplot_themed() +  \n  geom_point(\n    mapping = aes(\n      colour = hsv(hue, sat, .5), \n      size = map_size(val)\n    ), \n    show.legend = FALSE\n  )\n\n\n\n\nIn this code, the hsv() function takes the hue and saturation channels from the original image, but combines them with a constant intensity value: the output is a new colour specified as a hex code that ggplot2 can display in the output. Because we have stripped out the value channel, we can reuse the halftone trick. Much like a halftone image, the image above uses the size aesthetic to represent the intensity at the corresponding pixel.\nIntermission\nUp to this point I’ve talked about image manipulation, and I hope you can see the artistic potential created when we pair image processing tools like magick with data visualisation tools like ggplot2. What I haven’t talked about is how to choose (or generate!) the images to manipulate, and I haven’t talked about how we might introduce a probabilistic component to the process. I’m not going to say much about how to choose images. The possibilities are endless. For this post I’ve used a photo I took in my garden many years ago, but the pieces in Water Colours series have a different origin: I dripped some food colouring into a glass of water and took some photos of the dye diffusing. Small sections were cropped out of these photos and often preprocessed in some fashion by changing the hue, saturation etc. These manipulated photos were then passed into a noise generation process, and the output produced images like this:\n\n\n\n\n\n\n\n\nStorm Cell / Air Elemental\n\n\n\n\n\n\n\n\nTonal Earth\n\n\n\n\n\n\n\n\nCold Front\n\n\n\n\n\n\n\n\nKintsugi Dreams\n\n\n\n\n\n\nArt from noise generators\nMultidimensional noise generation\nHow can we generate interesting noise patterns in R? As usual, there are many different ways you can do this, but my favourite method is to use the ambient package that provides bindings to the FastNoise C++ library. A proper description of what you can do with ambient is beyond what I can accomplish here. There are a lot of things you can do with a tool like this, and I’ve explored only a small subset of the possibilities in my art. Rather than make a long post even longer, what I’ll do is link to a lovely essay on flow fields and encourage you to play around yourself.\nTo give you a sense of what the possibilities are, I’ve written a field() function that uses the ambient package to generate noise. At its heart is ambient::gen_simplex(), a function that generates simplex noise (examples here), a useful form of multidimensional noise that has applications in computer graphics. In the code below, the simplex noise is then modified by a billow fractal that makes it “lumpier”: that’s the job of ambient::gen_billow() and ambient::fracture(). This is then modified one last time by the ambient::curl_noise() function to avoid some undesirable properties of the flow fields created by simplex noise.\nIn any case, here is the code. You’ll probably need to read through the ambient documentation to understand all the moving parts here, but for our purposes the main things to note are the arguments. The points argument takes a data frame or tibble that contains the x and y coordinates of a set of points (e.g., something like the jas data!). The frequency argument controls the overall “scale” of the noise: does it change quickly or slowly as you move across the image? The octaves argument controls the amount of fractal-ness (hush, I know that’s not a word) in the image. How many times do you apply the underlying transformation?\n\n\nfield <- function(points, frequency = .1, octaves = 1) {\n  ambient::curl_noise(\n    generator = ambient::fracture,\n    fractal = ambient::billow,\n    noise = ambient::gen_simplex,\n    x = points$x,\n    y = points$y,\n    frequency = frequency,\n    octaves = octaves,\n    seed = 1\n  )\n}\n\n\n\nInterpreting the output of the field() function requires a little care. The result isn’t a new set of points. Rather, it is a collection of directional vectors that tell you “how fast” the x- and y-components are flowing at each of the locations specified in the points input. If we want to compute a new set of points (which is usually true), we need something like the shift() function below. It takes a set of points as input, computes the directional vectors at each of the locations, and then moves each point by a specified amount, using the flow vectors to work out how far to move and what direction to move. The result is a new data frame with the same columns and the same number of rows:\n\n\nshift <- function(points, amount, ...) {\n  vectors <- field(points, ...)\n  points <- points %>%\n    mutate(\n      x = x + vectors$x * amount,\n      y = y + vectors$y * amount,\n      time = time + 1,\n      id = id\n    )\n  return(points)\n}\n\n\n\nIt’s worth noting that the shift() function assumes that points contains an id column as well as the x and y columns. This will be crucial later when we want to merge the output with the jas data. Because the positions of each point are changing, the id column will be the method we use to join the two data sets. It’s also worth noting that shift() keeps track of time for you. It assumes that the input data contains a time column, and the output data contains the same column with every value incremented by one. In other words, it keeps the id constant so we know which point is referred to by the row, but modifies its position in time and space (x and y). Neat.\nArt from the noise\nTo illustrate how this all works, I’ll start by creating a regular 50x30 grid of points:\n\n\npoints_time0 <- expand_grid(x = 1:50, y = 1:30) %>% \n  mutate(time = 0, id = row_number())\n\nggplot_themed(points_time0) + \n  geom_point(size = .5)\n\n\n\n\nNext, I’ll apply the shift() function three times in succession, and bind the results into a single tibble that contains the the data at each point in time:\n\n\npoints_time1 <- shift(points_time0, amount = 1)\npoints_time2 <- shift(points_time1, amount = 1)\npoints_time3 <- shift(points_time2, amount = 1)\n\npts <- bind_rows(\n  points_time0, \n  points_time1, \n  points_time2,\n  points_time3\n)\n\n\n\nThen I’ll quickly write a couple of boring wrapper functions that will control how the size and transparency of the markers changes as a function of time…\n\n\nmap_size <- function(x) {\n  ambient::normalise(x, to = c(0, 2))\n}\nmap_alpha <- function(x) {\n  ambient::normalise(-x, to = c(0, .5))\n}\n\n\n\n…and now we can create some art:\n\n\npts %>% \n  ggplot_themed() +  \n  geom_point(\n    mapping = aes(\n      size = map_size(time), \n      alpha = map_alpha(time)\n    ),\n    show.legend = FALSE\n  )\n\n\n\n\nSo pretty!\nAccumulating art with purrr\n… but also so ugly. The code I used above is awfully inelegant: I’ve “iteratively” created a sequence of data frames by writing the same line of code several times. That’s almost never the right answer, especially when the code doesn’t know in advance how many times we want to shift() the points! To fix this I could write a loop (and contrary to folklore, there’s nothing wrong with loops in R so long as you’re careful to avoid unnecessary copying). However, I’ve become addicted to functional programming tools in the purrr package, so I’m going to use those rather than write a loop.\nTo solve my problem I’m going to use the purrr::accumulate() function, which I personally feel is an underappreciated gem in the functional programming toolkit. It does precisely the thing we want to do here: it takes one object (e.g., points) as input together with a second quantity (e.g., an amount), and uses the user-supplied function (e.g., shift()) to produce a new object that can, once again, be passed to the user-supplied function (yielding new points). It continues with this process, taking the output of the last iteration of shift() and using it as input to the next iteration, until it runs out of amount values. It is very similar to the better-known purrr::reduce() function, except that it doesn’t throw away the intermediate values. The reduce() function is only interested in the destination; accumulate() is a whole journey.\nSo let’s use it. The iterate() function below gives a convenient interface:\n\n\niterate <- function(pts, time, step, ...) {\n  bind_rows(accumulate(\n    .x = rep(step, time), \n    .f = shift, \n    .init = pts,\n    ...\n  ))\n}\n\n\n\nHere’s the code to recreate the pts data from the previous section:\n\n\npts <- points_time0 %>% \n  iterate(time = 3, step = 1)\n\n\n\nIt produces the same image, but the code is nicer!\n\n\n\nAssembling the parts\nAdding noise to jasmines coordinates\nThe time has come to start assembling the pieces of the jigsaw puzzle, by applying the flow fields from the previous section to the data associated with the jasmines image. The first step in doing so is to write a small extract_points() function that will take a data frame (like jas) as input, extract the positional information (x and y) and the identifier column (id), and add a time column so that we can modify positions over time:\n\n\nextract_points <- function(data) {\n  data %>% \n    select(x, y, id) %>% \n    mutate(time = 0)\n}\n\n\n\nHere’s how we can use this. The code below extracts the positional information from jas and then use the iterate() function to iteratively shift those positions along the paths traced out by a flow field:\n\n\npts <- jas %>% \n  extract_points() %>% \n  iterate(time = 20, step = .1)\n\n\n\nThe pts tibble doesn’t contain any of the colour information from jas, but it does have the “right kind” of positional information. It’s also rather pretty in its own right:\n\n\nmap_size <- function(x) {\n  ambient::normalise(x^2, to = c(0, 3.5))\n}\n\npts %>% \n  ggplot_themed() +  \n  geom_point(\n    mapping = aes(size = map_size(time)),\n    alpha = .01,\n    show.legend = FALSE\n  ) \n\n\n\n\nJoining the noise with jasmine colours\nWe can now take the pixels from the jasmines image and make them “flow” across the image. To do this, we’ll need to reintroduce the colour information. We can do this using full_join() from the dplyr package. I’ve written a small convenience function restore_points() that performs the join only after removing the original x and y coordinates from the jas data. The reason for this is that the pts data now contains the positional information we need, so we want the x and y values from that data set. That’s easy enough: we drop those coordinates with select() and then join the two tables using only the id column. See? I promised it would be useful!\n\n\nrestore_points <- function(jas, pts) {\n  jas %>% \n    select(-x, -y) %>% \n    full_join(pts, by = \"id\") %>% \n    arrange(time, id) \n}\n\n\n\nThe result is a tibble that looks like this:\n\n\njas <- restore_points(jas, pts)\njas\n\n\n# A tibble: 126,000 × 11\n   shade     id   red   grn   blu    hue   sat   val     x     y  time\n   <chr>  <int> <int> <int> <int>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 #838c…     1   131   140   112 0.220  0.200 0.549     1     1     0\n 2 #3c31…     2    60    49    35 0.0933 0.417 0.235     1    10     0\n 3 #503d…     3    80    61    61 0      0.237 0.314     1    11     0\n 4 #3631…     4    54    49    38 0.115  0.296 0.212     1    12     0\n 5 #443a…     5    68    58    48 0.0833 0.294 0.267     1    13     0\n 6 #8a68…     6   138   104    96 0.0317 0.304 0.541     1    14     0\n 7 #6658…     7   102    88    89 0.988  0.137 0.4       1    15     0\n 8 #5a5d…     8    90    93    81 0.208  0.129 0.365     1    16     0\n 9 #535c…     9    83    92    76 0.260  0.174 0.361     1    17     0\n10 #944b…    10   148    75    97 0.950  0.493 0.580     1    18     0\n# … with 125,990 more rows\n\nMore importantly though, it produces images like this:\n\n\nmap_size <- function(x, y) {\n  ambient::normalise((1 - x) * y^2, to = c(0, 5))\n}\n\njas %>% \n  ggplot_themed() +  \n  geom_point(\n    mapping = aes(\n      colour = hsv(hue, sat, .5), \n      size = map_size(val, time)\n    ), \n    alpha = .03,\n    show.legend = FALSE\n  )\n\n\n\n\nWhen colouring the image, we’re using the same “halftonesque” trick from earlier. The colours vary only in hue and saturation. The intensity values are mapped to the size aesthetic, much like we did earlier, but this time around the size aesthetic is a function of two variables: it depends on time as well as val. The way I’ve set it up here is to have the points get larger as time increases, but there’s no reason we have to do it that way. There are endless ways in which you could combine the positional, temporal, and shading data to create interesting generative art. This is only one example.\nThe last chapter\nAt last we have the tools we need to create images in a style similar (though not identical) to those produced by the Water Colours system. We can import, reorganise, and separate the data:\n\n\njas <- file %>% \n  import_image(width = 200, height = 120) %>% \n  construct_matrix() %>% \n  construct_tibble() %>% \n  extract_channels()\n\n\n\nWe can define flow fields with different properties, move the pixels through the fields, and rejoin the modified positions with the colour information\n\n\npts <- jas %>% \n  extract_points() %>% \n  iterate(\n    time = 40, \n    step = .2, \n    octaves = 10, \n    frequency = .05\n  )\n\njas <- jas %>%\n  restore_points(pts)\n\njas\n\n\n# A tibble: 984,000 × 11\n   shade    id   red   grn   blu    hue    sat   val     x     y  time\n   <chr> <int> <int> <int> <int>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 #9c8…     1   156   129   120 0.0417 0.231  0.612     1     1     0\n 2 #81b…     2   129   181   100 0.274  0.448  0.710     1    10     0\n 3 #8b7…     3   139   120   112 0.0494 0.194  0.545     1   100     0\n 4 #eed…     4   238   223   219 0.0351 0.0798 0.933     1   101     0\n 5 #c29…     5   194   154   163 0.962  0.206  0.761     1   102     0\n 6 #d5e…     6   213   225   195 0.233  0.133  0.882     1   103     0\n 7 #bde…     7   189   232   190 0.337  0.185  0.910     1   104     0\n 8 #b3d…     8   179   223   188 0.367  0.197  0.875     1   105     0\n 9 #b2d…     9   178   220   189 0.377  0.191  0.863     1   106     0\n10 #b3d…    10   179   217   191 0.386  0.175  0.851     1   107     0\n# … with 983,990 more rows\n\nWe can write customised helpers to guide how information is used:\n\n\nmap_size <- function(x, y) {\n  12 * (1 - x) * (max(y)^2 - y^2) / y^2\n}\n\n\n\nAnd we can render the images with ggplot2:\n\n\npic <- jas %>% \n  ggplot_themed() +  \n  geom_point(\n    mapping = aes(\n      colour = shade, \n      size = map_size(val, time)\n    ), \n    alpha = 1,\n    stroke = 0,\n    show.legend = FALSE\n  ) \n\npic\n\n\n\n\nThe colour bleeding over the edges here is to be expected. Some of the points created with geom_point() are quite large, and they extend some distance beyond the boundaries of the original jasmines photograph. The result doesn’t appeal to my artistic sensibilities, so I’ll adjust the scale limits in ggplot2 so that we don’t get that strange border:\n\n\npic +\n  scale_x_continuous(limits = c(11, 190), expand = c(0, 0)) +\n  scale_y_continuous(limits = c(7, 114), expand = c(0, 0))\n\n\n\n\nThe end result is something that has a qualitative similarity to the Water Colours pieces, but is also possessed of a style that is very much its own. This is as it should be. It may be true that “all art is theft” – as Picasso is often misquoted as saying – but a good artistic theft is no mere replication. It can also be growth, change, and reconstruction.\nA happy ending after all.\nEpilogue\n\nI find it so amazing when people tell me that electronic music has no soul. You can’t blame the computer. If there’s no soul in the music, it’s because nobody put it there (Björk, via Tim de Sousa)\n\n\n\n\n\n\n\n\n\nDeparture\n\n\n\n\n\n\n\n\nEcho\n\n\n\n\n\n\n\n\nPortal\n\n\n\n\n\n\n\n\nGods of Salt, Stone, and Storm\n\n\n\n\n\n\n\n\nEl Último Amanecer de Invierno\n\n\n\n\n\n\n\n\nPlume\n\n\n\n\n\n\n\n\nWoodland Spirits\n\n\n\n\n\n\n\n\nBelow the Horizon\n\n\n\n\n\n\n\n\nLast updated\n\n\n2021-09-13 15:59:30 AEST\n\n\nDetails\n\n\n\nsource code\n, \nR environment\n\n\n\n\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-09-07_water-colours/jasmine-recollected.png",
    "last_modified": "2021-09-13T15:59:31+10:00",
    "input_file": "index.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-08_git-credential-helpers/",
    "title": "Managing GitHub credentials from R, difficulty level linux",
    "description": "A sick sad story in which a humble R user was forced to learn something about\nhow linux stores passwords and, more importantly, got R to use her GitHub\ncredentials properly",
    "author": [
      {
        "name": "Danielle Navarro",
        "url": "https://djnavarro.net"
      }
    ],
    "date": "2021-08-08",
    "categories": [],
    "contents": "\n\nContents\nThe story is quite short…\nUsing GitHub credentials with R\nSetting up the credentials\n\n… unless you’re on linux\nWhere did I leave my config?\nDon’t forget to update git\n\nThree solutions\n1. Set a long timeout for the git cache\n2. Use libsecret credential manager\n3. Use GCM core\n\n\n\n\nThere are days when I regret switching to linux as an R user. It’s not that I’m particularly enamoured of Apple or Microsoft, and I do enjoy the freedom to tinker that linux systems provide, but without the same resourcing that underpins Windows or Mac OS, I do spent a disproportionate amount my time trying to make my long-suffering Ubuntu laptop do something that would “just work” if I’d gone with one of the more traditional options. But such is life, and besides, there’s a case to be made that the time I spend on these things is not wasted: usually, I end up learning something useful.\n La la la la la. (Figure from giphy.com)\nThis is one of those stories.\nThe story is quite short…\nUsing GitHub credentials with R\nFor some years now I have been using git repositories for version control, with some ambivalence to my feelings. I absolutely love version control, and I think GitHub is a fabulous tool, but git itself gives me headaches. It feels counterintuitive and untidy, and I am resistant to learning new git tricks because of that. However, now that GitHub is moving to end password authentication for git operations, I find myself needing to do precisely that. Sigh.\nLike many R users, whenever I encounter a git problem my first impulse is to see whether Happy Git and GitHub for the useR (Bryan 2018) can help me out, and true to form, it can. Having decided that I will revert to being an https girl, renouncing my flirtation with ssh, I’ve found the chapter on caching https credentials extremely useful. The usethis article on git credentials is also worth the read.\nThe problem can be broken into three parts:\nHow do I set up an authentication token on my GitHub account?\nHow do I configure my git installation to use the authentication token?\nHow do I ensure that R detects these credentials?\nThanks to the fabulous work of the tidyverse team, it’s possible for R users to solve the problem in a fairly painless way. The solution has been documented repeatedly, but for the sake of completeness I’ll repeat the advice here.\nSetting up the credentials\nThe first thing you’ll need to do is set up a GitHub token. You can do this on the GitHub website, but for an R user it’s probably easiest to use the usethis package (Wickham and Bryan 2021):\n\n\nusethis::create_github_token()\n\n\n\nThis will open GitHub in a browser window, take you to the “create a new token page,” and pre-populate all the fields with sensible default values. After accepting these values, the token is created and you’ll be given a PAT, a “personal authentication token.” It’ll look something like this…\nghp_dgdfasdklfjsdklfjsadfDKFJASDLKFJ3453\n…and you should immediately save this in a secure password manager, like 1password, lastpass, etc, because GitHub will only show it to you this one time. You did save it to your password manager, right? Right? I mean, you might need it again. You really might. Yes, you. All right then. I’ll trust you’ve taken sensible precautions now, so let’s keep going. The next step in the process is to configure your git installation to use your token. This is, once again, quite easy to do with gitcreds (Csárdi 2020):\n\n\ngitcreds::gitcreds_set()\n\n\n\nWhen you call this function interactively, R will ask for your PAT. Paste it into the console, hit enter, and you are done. Your git installation is now configured to use the token. Yay! Let’s move onto the third step, which is to ensure that R will recognise and use these credentials. As it turns out, step three doesn’t require you to do anything, because it happens automatically! Functions like usethis::pr_push() recognise your credentials as soon as gitcreds sets them up, and everything works perfectly…\n Quinn. (Figure from giphy.com)\n… unless you’re on linux\nIf you’re on linux, you might find yourself in the same boat I was. The credentials you just set up work flawlessly for about 15 minutes, at which time R complains that it cannot find any credentials and you spend the next 15 minutes crying melodramatically.\nWhen this happened to me I assumed the problem was my R environment. I tried updating gitcreds, usethis, and every other R package I could think of that might possibly be involved in communicating with git. Nothing worked. The reason nothing worked is that the problem wasn’t with R at all… it was git, and in hindsight I realise that the problem is specific to git on linux. All those beautiful people with their fancy Windows and Mac machines won’t run into the problem I encountered. They won’t spend an entire Saturday trying to teach themselves git credential management. They will never know my pain. Curse them and their superior purchasing decisions.\n Daria. (Figure from giphy.com)\nJust kidding. I love my quirky little Ubuntu box and I have a lot of fun learning how to fix her up every time she sets herself on fire.\nWhere did I leave my config?\nOkay, I’m going to need to make changes to my git configuration. Although git makes it possible to store configuration locally, at the repository level, I rarely need this flexibility. The relevant information is stored in the global configuration file: on my machine, this is located at /home/danielle/.gitconfig. I can use git config to list these configuration settings, like this\n\ngit config --global --list\n\nand at the start of this exercise the output would have looked like this:\nuser.name=Danielle Navarro\nuser.email=d.navarro@unsw.edu.au\nI’m not sure why this is, but I always feel slightly more reassured when I’m able to inspect the configuration file itself. Opening my .gitconfig file shows the same information, but the formatting is slightly different in the raw file:\n[user]\n    name = Danielle Navarro\n    email = d.navarro@unsw.edu.au\nTo solve the git credential problem, we’re going to need to edit this configuration information. Depending on which solution you go with, you might need to install new software too.\nDon’t forget to update git\nBefore starting, it’s a good idea to make sure you have the latest version of git: older versions may not have the tools you need. As it happens, I had already updated git to the most recent version (2.32.0 at the time of writing), but in case anyone ends up relying on this post, here’s how you do it:\nsudo add-apt-repository ppa:git-core/ppa\nsudo apt update\nsudo apt install git\nThree solutions\n1. Set a long timeout for the git cache\nRecent versions of git are released with a credential cache that retains your credentials in memory temporarily. The information is never written to disk, and it expires after a time. You can tell git to use this cache as your “credential helper” by typing the following command at the terminal:\n\ngit config --global credential.helper cache\n\nAfter doing this, my .gitconfig file now looks like this:\n[user]\n    name = Danielle Navarro\n    email = d.navarro@unsw.edu.au\n[credential]\n    helper = cache\nUnfortunately this isn’t an ideal solution, because the cache expires after 900 seconds (15 minutes). As soon as the cache expires, git loses track of your GitHub credentials and so does R. So you have to set the credentials again by calling gitcreds::gitcreds_set() and entering the PAT again. That’s annoying, but you did store the PAT in a password manager right? You were smart. You definitely aren’t going to be foolish like me, forget to store your PAT every time, and end up needing to create a new GitHub token every 15 minutes.\nA simple solution to this problem is to ask git to store information in the cache for just a teeny tiny little bit longer. Instead of having the cache expire after the default 900 seconds, maybe set it to expire after 10 million seconds. That way, you’ll only have to refresh the cache using gitcreds::gitcreds_set() once every four months instead of four times an hour. Implementing this solution requires only one line of code at the terminal:\n\ngit config --global credential.helper 'cache --timeout=10000000'\n\nAfter typing this, my .gitconfig file looks like this:\n[user]\n    name = Danielle Navarro\n    email = d.navarro@unsw.edu.au\n[credential]\n    helper = cache --timeout=10000000\nIn some ways this is a bit of a hack. If cache expiry normally happens every 15 minutes, there’s something a little odd about dragging it out and making it hang around for 16 weeks. That being said, I’ve done many stranger things than this in my life. It may not be the most elegant way to solve the problem, but it works.\n Trent. (Figure from giphy.com)\n2. Use libsecret credential manager\nIt puzzled me slightly that this problem only exists for linux computers, so I did a little more reading on how git manages credentials. It turns out you don’t have to rely on the in-memory cache: you can tell git to use some other program to supply the credentials. This is what all those swanky Mac and Windows people have been doing all along. On Macs, for example, git defaults to using the OS X keychain to store credentials safely on disk. It’s possible to do the same thing on linux using libsecret (source on gitlab) and thankfully it’s not much harder to set this up than to use the “long cache” trick described in the previous section.\nThe first step is ensuring libsecret is installed on your machine. It probably is (or at least, it was on my Ubuntu 20.04 box), but in case it isn’t here’s the command you need\n\nsudo apt install libsecret-1-0 libsecret-1-dev\n\nIt helps to realise that libsecret isn’t an application designed to work with git (i.e., it’s not the credential manager), nor is it the keyring where the passwords are stored. Rather, it’s a library that communicates with the keyring: I found this post useful for making sense of it. So if we want to use libsecret to access the keyring, we’re going to need a git credential manager that knows how to talk to libsecret. As it turns out, git comes with one already, you just have to build it using make:\n\ncd /usr/share/doc/git/contrib/credential/libsecret\nsudo make\n\nThis will build the git-credential-libsecret application for you and now all you have to do is tell git to use this as the “credential helper” application that supplies the GitHub credentials:\n\ngit config --global credential.helper \\\n  /usr/share/doc/git/contrib/credential/libsecret/git-credential-libsecret\n\nAfter typing that, my .gitconfig file looks like this…\n[user]\n    name = Danielle Navarro\n    email = d.navarro@unsw.edu.au\n[credential]\n    helper = /usr/share/doc/git/contrib/credential/libsecret/git-credential-libsecret\n… and I’m all set and ready to go.\nOne thing I found handy during this step is to check that R was reading the correct configuration information. It’s possible to do this with gitcreds:\n\n\ngitcreds::gitcreds_list_helpers()\n\n\n\n\n[1] \"/usr/share/doc/git/contrib/credential/libsecret/git-credential-libsecret\"\n\nIn any case, if all the applications are talking to each other properly, the next time you call gitcreds::gitcreds_set() they’ll all send the message along: R will pass your PAT to git, git will pass it to git-credential-libsecret, git-credential-libsecret will pass it to libsecret, and the PAT will end up in your linux keychain. Whenever you need to authenticate and push some commits up to GitHub from R, it should find the credentials using the same communication channel. Everything should work swimmingly.\n Quinn et al. (Figure from giphy.com)\n3. Use GCM core\nAs far as I can tell, the libsecret credential manager is a perfectly good solution to the problem, but in the end I made a different choice: I decided to go with “git credential manager core,” or GCM Core. It’s developed by Microsoft and, perhaps unsurprisingly, it is what GitHub currently recommends. It’s slightly more painful to set up, and the installation instructions are different depending on what flavour of linux you’re running. Because I’m on Ubuntu 20.04, I downloaded the .deb file associated with the most recent release of GCM core, and then installed the application using the dpkg command:\n\nsudo dpkg -i <path-to-deb-file>\n\nThis will build GCM core on your system, and once that’s done you can ask it to take care of the git configuration for you:\n\ngit-credential-manager-core configure\n\nThis will edit the .gitconfig file, so for me it now looks like this:\n[user]\n    name = Danielle Navarro\n    email = d.navarro@unsw.edu.au\n[credential]\n    helper = \n    helper = /usr/bin/git-credential-manager-core\n[credential \"https://dev.azure.com\"]\n    useHttpPath = true\nIn a happier world you would be done at this point, but we don’t live in a happy world. We live in a sick sad world that has global pandemics and pineapple on pizzas. So there’s still one job left to do.\nMuch like the libsecret credential manager I built in the previous section, GCM core is “just” a git credential manager: it communicates with git, but it isn’t a password manager or a keyring, and it doesn’t store the PAT itself. Instead, it offers you several different options for how the PAT is to be stored. If you click through and take a look at the list, the first suggested option is to connect to a secret service API. As far as I can tell “secret service” isn’t an application, it’s a specification, and in practice it’s just a fancy way of referring to a linux keychain. Just as the libsecret credential manager needs some way of communicating with the keychain (i.e., the libsecret library itself), GCM core needs an intermediary. In fact, it turns out GCM core also uses libsecret to talk to the keychain. So that’s the option I went with. The terminal command to set this up is this:\n\ngit config --global credential.credentialStore secretservice\n\nAfter running the command, my .gitconfig file looks like this:\n[user]\n    name = Danielle Navarro\n    email = d.navarro@unsw.edu.au\n[credential]\n    helper = \n    helper = /usr/bin/git-credential-manager-core\n    credentialStore = secretservice\n[credential \"https://dev.azure.com\"]\n    useHttpPath = true\n Jane. (Figure from giphy.com)\nAs before, I can check that R is reading the correct configuration information…\n\n\ngitcreds::gitcreds_list_helpers()\n\n\n[1] \"/usr/bin/git-credential-manager-core\"\n\n…and now I’m ready to go. My problems are solved. The sun is shining, the birds are singing, and git is working properly from R again. All is well in heaven and earth. Oh the sheer excitement of it all. I hope I can contain my boundless enthusiasm and joy.\n Daria. (Figure from giphy.com)\n\nLast updated\n\n\n2021-09-13 16:37:45 AEST\n\n\nDetails\n\n\n\nsource code\n, \nR environment\n\n\n\n\n\n\n\n\n\n\n\nBryan, Jennifer. 2018. Happy Git and GitHub for the useR. GitHub.\n\n\nCsárdi, Gábor. 2020. Gitcreds: Query ’Git’ Credentials from ’r’. https://CRAN.R-project.org/package=gitcreds.\n\n\nWickham, Hadley, and Jennifer Bryan. 2021. Usethis: Automate Package and Project Setup. https://CRAN.R-project.org/package=usethis.\n\n\n\n\n",
    "preview": "posts/2021-08-08_git-credential-helpers/credentials.jpg",
    "last_modified": "2021-09-13T16:37:46+10:00",
    "input_file": "index.knit.md"
  },
  {
    "path": "posts/2021-07-08_generative-art-in-r/",
    "title": "Generative art in R",
    "description": "Comments on an exhibit I contributed to as part of useR!2021",
    "author": [
      {
        "name": "Danielle Navarro",
        "url": "https://djnavarro.net"
      }
    ],
    "date": "2021-07-08",
    "categories": [],
    "contents": "\n\n\nA little while ago I was invited by Sara Mortara to contribute art as part of an exhibit to be presented at the 2021 useR! conference, along with several artists who I admire greatly. I could hardly say no to that, now could I? So I sent some pieces that I’m fond of, most of which are posted somewhere on my art website. I realised later though that I was going to have to talk a little about my art too, and Sara suggested an informal Q&A during the timeslot allocated to the exhibit. Naturally, I agreed since that meant I didn’t have to prepare anything formal, and like all artists I am extremely lazy. Later though, it occurred to me that it actually wouldn’t be terrible if I wrote a blog post to accompany my contribution to the exhibit, loosely based on the questions Sara suggested. And so here we are…\nWhen did you start using R for art? Do you remember your first piece?\nI started making art in R some time in late 2019. I’d discovered some of the art that Thomas Lin Pedersen had been making – at the time he was posting pieces from his Genesis series – and at the same time I found the ambient package that he was using to create the pieces. Thomas famously does not post source code for his art, and being stubborn and curious I wanted to work out how he was doing it, so I started playing with ambient to see if I could reverse engineer his system. My very first piece was Constellations, shown below. It’s certainly not the prettiest thing I’ve created, and there are a lot of things I’d like to change about it now, but it’s nice to have your early work lying around to see how you’ve changed since then:\n\nConstellations\n\nIf you follow the link above and look at Thomas’ Genesis pieces you can tell that it’s not even remotely close to the mark, but I did eventually get the hang of it and managed to produce a few pieces like Rainbow Prisms which are closer to the kind of work he was producing:\n\nRainbow Prisms\n\nIt’s still not quite the same as Thomas’ in style, but by the time I’d worked out how to produce these I decided it was time to change my approach and branch out a bit. I love Thomas’ work of course, but I didn’t want my art to be just a low quality imitation of his! And besides, by that point I’d started discovering a whole lot of other people making generative art in R, such as Will Chase, Antonio Sánchez Chinchón, Marcus Volz, and (somewhat later) Ijeamaka Anyene. Each has their own style and – following the famous advice that art is theft – have shamelessly taken ideas and inspiration from each at different times.\nSome of those early pieces are still around, as part of the Rosemary gallery.\nWere you an artist before making generative art in R?\nNot really. I always wanted to do more artistic and creative things, but the only thing I’d ever done that required any kind of mix of aesthetic sensibility and craftwork was gardening. I used to have a lovely garden in Adelaide with a mix of Mediterranean and Australian native plants, and I had the same kind of enthusiasm for gardening then as I do for art now. Maybe one day I’ll garden again but there’s no space for that in my Sydney apartment!\nCan you talk about your creative process? Do you begin from code or from the outcome you are looking for? Do you start with the color palette in mind, or is it an iterative process?\nI’m honestly not sure I have a consistent process? I spend a lot of time browsing artwork by other people on twitter and instagram, and from time to time I read posts about the techniques that they use. Whenever I do this I end up thinking a bit about how I might use this technique or wondering what methods other artists use to create their work, but I don’t usually act on that information until I think of something I want to do with it. That kind of technical or stylistic information is like background knowledge that lies dormant until I need it.\nMost of the time the starting point for my art is an emotion. I might be angry or lonely or tired, or just in need of something to occupy my mind and distract me from something else. When I start implementing a new system it’s often (though not always) a modification of a previous one. In principle this modification process could go in any direction, but my aesthetic sensibilities depend a lot on my state of mind, and that imposes a bias. I tweak the code one way, and see what it produces. If I like it, I keep the change, if I don’t I reject it. It’s a lot like a Metropolis-Hastings sampler that way, but my mood strongly shapes the accept/reject decision, so the same starting point can lead to different outcomes. As a concrete example, the Pollen, Bursts and Embers series are all based on the same underlying engine, the fractal flame algorithm created by Scott Draves, but my emotional state was very different at the time I coded each version. For example, the Pollen Cloud piece I contributed to the useR exhibit is soft and gentle largely because I was feeling peaceful and relaxed at the time:\n\nPollen Cloud\n\nBy way of contrast, the Geometry in a Hurricane piece from Bursts is layered in jagged textures with a chaotic energy because I was angry at the time I was coding:\n\nGeometry in a Hurricane\n\nThe Soft Ember piece below (also included in the exhibit) has a different feel again. There’s more energy to it than the pollen pieces, but it’s not as chaotic as the bursts series. Again, that’s very much a reflection of my mood. I wasn’t angry when I coded this system, but I wasn’t relaxed either. At the time, something exciting had happened in my life that I wasn’t quite able to do anything about, but I was indulging in the anticipation of a new thing, and some of that emotion ended up showing through in the pieces that I made at the time:\n\nSoft Ember\n\nTo bring all this back to the question, it’s very much an iterative process. The driver behind the process is usually an emotion, and the colour choices, the shapes, and the code are all adapted on the fly to meet with how I’m feeling.\nWhat is your inspiration?\nTo the extent that my art is driven by emotion, the inspiration for it tends to be tied to sources of strong emotion in my life. Sometimes that emotion comes from the sources of love and joy: family, intimate partners, and so on. The Heartbleed series is one of those. The background texture to these images is generated by simulating a simple Turing machine known as a turmite and the swirly hearts in the foreground are generated using the toolkit provided by the ambient package. This system is very much motivated from emotional responses to the loved ones in my life. One of the pieces in the exhibit is from this series:\n\nTurmite 59 in Red\n\nOther times the emotional motivation comes from sources of pain - sometimes things that were physically painful, sometimes that were psychologically painful. The Orchid Thorn piece I included in the exhibit is one of those, linked to an intense physically painful experience.\n\nOrchid Thorn\n\nThe Bitterness piece below, which I haven’t done much with other than post to my instagram, is strongly tied to the psychological stresses associated with my gender transition. Yes, there’s a softness to the piece, but there’s also a sandpaper-like texture there that makes me think of abrasion. The colour shifts make me think about transitions, but the roughness at some of the boundaries reminds me that change is often painful.\n\nBitterness\n\nOne odd property of the art, at least from my point of view, is that looking at a given piece recalls to mind the events and emotions that inspired the work, and to some extent that recollection becomes a way of re-experiencing the events. Sometimes that’s a good thing. Not always though.\nWhat is your advice for people who wants to create art in R?\nI think I’d suggest three things. Find artists you like, read about their processes. Sometimes they’ll show source code or link to algorithms like I’ve done in a few places in this piece, and it can be really valuable to try to retrace their steps. There’s nothing wrong with learning technique by initially copying other artists and then developing your own style as you go.\nThe second thing I’d suggest, for R folks specifically, is to take advantage of the skills you already have. Most of us have skills in simulation, data wrangling, and data visualisation, and those skills can be repurposed for artistic work quite easily. A lot of my pieces are created using that specific combination. I’ll often define a stochastic process and sample data from it using tools in base R, use dplyr to transform and manipulate it, then use ggplot2 to map the data structure onto a visualisation. One of the nice things about dplyr and ggplot2 being compositional grammars is the fact that you can “reuse” their parts for different purposes. I get a lot of artistic mileage out of geom_point() and geom_polygon(), and quite frankly purrr is an absolute godsend when the generative process you’re working with is iterative in nature.\nThe other thing would be try not to put pressure on yourself to be good at it immediately. I wasn’t, and I don’t think anyone else was either. Earlier I showed the Constellations piece and referred to it as the first piece I created. In a way that’s true, because it was the first time I reached a level that I felt comfortable showing to other people. But I made a lot of junk before that, and I made a lot of junk after that. I make some good art now (or so people tell me) precisely because I made a lot of bad art before. Even now, though, I can’t tell which systems will end up good and which will end up bad. It’s a bit of a lottery, and I’m trying my best not to worry too much about how the lottery works. I like to have fun playing with visual tools, and sometimes the tinkering takes me interesting places.\nAnything to add about your pieces in the exhibit?\nNot a lot. Several of the pieces I’ve contributed are already linked above, but I might just say a little about the other pieces and how they were made. The Silhouette in Teal piece uses the flametree generative art package to create the tree shown in silhouette in the foreground, and a simple random walk to generate the texture in the background:\n\nSilhouette in Teal\n\nIt has also been surprisingly popular on my Society6 store, which you can visit if you want some of my art on random objects. I am not sure why, but I have sold a lot more shower curtains and yoga mats than I would have expected to sell in my lifetime.\nLeviathan emerged from my first attempt to create simulated watercolours in R using this guide written by Tyler Hobbs. I was in a dark mood at the time and the ominous mood to the piece seems quite fitting to me.\n\nLeviathan\n\nThe Floral Effect piece is an odd one. It’s part of the Viewports series that I created by applying Thomas Lin Pedersen’s ggfx package over the top of the output of the same system I used to create the Native Flora series, which in turn is an application of the flametree system I mentioned earlier. I quite like it when these systems build on top of one another.\n\nFloral Effect\n\nThe last piece I included, Fire and Ice, is a little different from the others in that it’s not a “pure” generative system. It works by reading an image file into R, using Chris Marcum’s halftoner package to convert it to a halftone image, and then manipulate that image using the tools provided in the ambient package. The end result is something that still resembles the original image but has more of a painted feel:\n\nFire and Ice\n\n\n\nLast updated\n\n\n2021-09-13 16:37:17 AEST\n\n\nDetails\n\n\n\nsource code\n, \nR environment\n\n\n\n\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-07-08_generative-art-in-r/turmite59-in-red.jpg",
    "last_modified": "2021-09-13T16:37:17+10:00",
    "input_file": "index.knit.md"
  },
  {
    "path": "posts/2021-04-19_bs4cards-in-distill/",
    "title": "Bootstrap cards in distill",
    "description": "How to enable bootstrap 4 on a distill website, even though you probably \ndon't need to. I like it though because I get to add pretty bootstrap cards",
    "author": [
      {
        "name": "Danielle Navarro",
        "url": "https://djnavarro.net"
      }
    ],
    "date": "2021-04-19",
    "categories": [],
    "contents": "\n\nContents\nEnabling bootstrap 4\nVanilla R markdown\nPkgdown\nDistill\n\nTesting with pretty pictures\n\n\n\nWhen creating R markdown websites, I often find myself wanting to organise content into a nice-looking grid of links. For example, in a recent project I wanted to be able to create something like this:\n\n\n\n\n\n\n\n\nStarting R markdown\n\nAn introduction to R markdown. The target audience is a novice R user with no previous experience with markdown.\n\n\n\n\n\n\n\nStarting ggplot2\n\nAn introduction to ggplot2. The target audience is a novice user with no previous experience with R or ggplot2.\n\n\n\n\n\n\n\nStarting programming\n\nThis is primarily a tutorial on making generative art in R, but in doing so introduces core programming constructs and data structures. It is assumed the user has some previous experience with ggplot2.\n\n\n\n\n\nIt bothered me that this wasn’t as straightforward as I was expecting, so for one of my side projects I’ve been putting together a small package called bs4cards to make this a little easier inside an R markdown document or website. There are some introductory articles posted on the bs4cards package website showing how the package works, and there’s no need to duplicate that content here. However, because this website uses the distill package (Allaire et al. 2021) and the package website is built using pkgdown (Wickham, Hesselberth, and Salmon 2021), it seems like a good idea to have at least one post on both sites that uses bs4cards.\nEnabling bootstrap 4\nThe reason for doing this is that the first step in using the package is to make sure that your R markdown document uses version 4 of bootstrap: the bs4cards package takes its name from the cards system introduced in bootstrap version 4, and will not work properly if used in R markdown documents that rely on bootstrap version 3, or don’t use bootstrap at all. To ensure that you are using bootstrap 4, you need to edit the YAML header for your document to specify which version of bootstrap you want to use. The instructions are slightly different depending on what kind of document you’re creating:\nVanilla R markdown\nFor a plain R markdown document or website (i.e., one where the output format is html_document) here is the relevant section of YAML you might use:\noutput:\n  html_document:\n    theme:\n      version: 4\nThis overrides the R markdown defaults (Xie, Dervieux, and Riederer 2020) to ensure that the output is built using bootstrap 4.5.\nPkgdown\nTo enable bootstrap 4 in a pkgdown site, the process is similar but not identical. Edit the _pkgdown.yml file to include the following\ntemplate:\n  bootstrap: 4\nNote that this relies on a currently-in-development feature, so you may need to update to the development version of pkgdown to make this work.\nDistill\nDistill R markdown does not use bootstrap, which is a little inconvenient if you want to use bs4cards with distill. With a little effort it is possible to enable the entire bootstrap library in a distill site, but this can lead to undesirable side-effects because bootstrap has a lot of styling that doesn’t look visually appealing when mixed with the istill styling. The solution I’ve adopted for this is to use a custom bootstrap build that includes a minimal number of bootstrap components. If you want to try the same approach, you can download the strapless.css file to the same folder as the distill post you want to enable it for, and include the following YAML in the post header:\noutput:\n  distill::distill_article:\n    css: \"strapless.css\"\nIf you want to enable strapless for the entire site, this markup goes in the _site.yml file and the css file should go in the home folder for the project. Once that’s done you should be ready to go. That being said, you’d be wise to be careful when adopting this approach: the strapless build is a crude hack, and I haven’t tested it very thoroughly.\nTesting with pretty pictures\nJust to make certain, let’s check that it does what we want by generating cards using the galleries data that comes bundled with the bs4cards package:\n\n\nlibrary(bs4cards)\ngalleries %>% \n  cards(title = long_name, image = image_url)\n\n\n\n\n\n\nAsh Cloud and Blood\n\n\n\n\nGhosts on Marble Paper\n\n\n\n\nIce Floes\n\n\n\n\nNative Flora\n\n\n\n\nSilhouettes\n\n\n\n\nTrack Marks\n\n\n\n\nViewports\n\n\n\n\n\n\nLooks about right to me?\n\n\nLast updated\n\n\n2021-09-13 16:49:06 AEST\n\n\nDetails\n\n\n\nsource code\n, \nR environment\n\n\n\n\n\n\n\n\n\n\n\nAllaire, JJ, Rich Iannone, Alison Presmanes Hill, and Yihui Xie. 2021. Distill: ’R Markdown’ Format for Scientific and Technical Writing. https://CRAN.R-project.org/package=distill.\n\n\nWickham, Hadley, Jay Hesselberth, and Maëlle Salmon. 2021. Pkgdown: Make Static HTML Documentation for a Package.\n\n\nXie, Yihui, Christophe Dervieux, and Emily Riederer. 2020. R Markdown Cookbook. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown-cookbook.\n\n\n\n\n",
    "preview": "posts/2021-04-19_bs4cards-in-distill/bs4cards-logo.png",
    "last_modified": "2021-09-13T16:49:06+10:00",
    "input_file": "index.knit.md",
    "preview_width": 2820,
    "preview_height": 1620
  },
  {
    "path": "posts/2021-04-18_pretty-little-clis/",
    "title": "Pretty little CLIs",
    "description": "How to make a gorgeous command line interface in R using the cli package.\nSomewhere along the way I accidentally learned about ANSI control codes,\nwhich strikes me as unfortunate",
    "author": [
      {
        "name": "Danielle Navarro",
        "url": "https://djnavarro.net"
      }
    ],
    "date": "2021-04-18",
    "categories": [],
    "contents": "\n\nContents\nMeet the cli package\nUsing the status bar\nCreating spinners\nShowing cli messages in R markdown\nWriting longer messages\nCreating structured messages\nEpilogue\n\n\n\n\n\n\n\nLyrics to the title theme of the US TV show, Pretty Little Liars. The song is called Secrets, taken from the fabulous Thirteen Tales of Love and Revenge album by The Pierces\nAnytime you write R code whose output needs to be understood by a human being, it is an act of kindness to spend a little time making sure that the output shown to the human being properly communicates with that human. As a consequence of this, you often find yourself needing to write information to the R console, just to cater to those precious human sensibilities. Perhaps the simplest way to do this is to use the cat() function. It’s a simple tool and it gets the job done in most cases.\nFor example, consider the use case for the antagonist character “A” from Pretty Little Liars, whose stalking and threats were delivered mostly via text message. Had she used R to craft her threatening text messages, she could have written code like this:\n\n\nwait <- function(seconds = 2) {\n  Sys.sleep(seconds)\n}\n\nsend_cat_threat <- function() {\n  cat(\"Dead girls walking.\\n\"); wait()\n  cat(\"--A.\\n\")\n}\n\n\n\nEquipped with a function that specifies her threat, complete with a dramatic pause for effect, she’s ready to go. When her unwitting victim does something to trigger the send_cat_threat() function, a two part message is displayed on the console. The first part shows up immediately\n\nDead girls walking.\n\nand after a two second delay, her call sign is revealed\n\nDead girls walking.\n--A.\n\nIt’s not too difficult to imagine what this message might look like at the R console, but where’s the fun in that? Thanks to the asciicast package (Csárdi et al. 2019), there’s no need to leave anything to the imagination, and we can see the malevolent message in screencast form:\n\n\n\n\nThe ominous text messages used in this post are taken from Pretty Little Liars. This one is from episode two in season one. It’s important that one documents ones sources, right?\nUsing cat() to craft messages works perfectly well for simple text communication, but sometimes you want something that looks a little fancier. After all, if the big picture plan here is to impersonate a dead teenager and terrorise her friends - and for some reason you’ve chosen R to do so - you might as well put a little effort into the details, right?\nMeet the cli package\nOne thing I love about the R community is that if you search long enough you’ll find that someone else has already written a package that solves the problem you’re facing. If your problem is “how to craft nicely formatted messages” then you’ll be delighted to learn that many wonderful things become possible if you have the cli package (Csárdi 2021a) as your talented assistant. To craft a beautiful command line interface (CLI) of her very own, the first thing A will need to do is load the package:\n\n\nlibrary(cli)\n\n\n\nOnce this is done, it is a very trivial task for A to write the same threatening text message using cli_text()…\n\n\nsend_cli_threat <- function() {\n  cli_text(\"Dead girls walking.\"); wait()\n  cli_text(\"--A.\")\n}\nsend_cli_threat()\n\n\n\n\n\n\n…which is nice and all, but it doesn’t make much of a case for using cli. Stalking and threatening is busy work, and I’d imagine that A would want a more compelling justification before deciding to switch her evil workflow. However - much like A herself - the R console has many dark secrets, and fancier tricks than this are possible once you know how to expose them using cli.\nUsing the status bar\nOne piece of magic that I have wondered about for a long time is how fancy progress bars work: often when you’re doing something that takes a long time, you’ll see an ASCII progress bar rendered in text on the screen, which suddenly vanishes once the process is complete. How exactly does this work? Normally you can’t “unprint” a message from the console, so how is it possible for the progress bar to update without leaving an ugly trail of earlier messages behind it?\nWhile teaching myself cli, I found the answer. The most recent line of text generated at the terminal is speciall. It’s called the status bar: the state of the status bar can be manipulated, and the cli package provides a neat toolkit for doing so. So let’s say I were trying to convince A to switch to the cli tools. Right now, she’s writing a function that will send a four-part message, using cli_text() because I’ve at least convinced her to try the new tools:\n\n\nmessage_scroll <- function() {\n  cli_text(\"You found my bracelet.\"); wait()\n  cli_text(\"Now come find me.\"); wait()\n  cli_text(\"Good luck bitches.\"); wait()\n  cli_text(\"-A\"); wait()\n}\nmessage_scroll()\n\n\n\nWhen her victim triggers this message the lines will appear on screen, one after the other with an appropriate dramatic pause separating them. The victim might see something that looks like this:\n\n\n\nThe problem – when viewed from an evil point of view – is that this message stays on screen after delivery.1 The victim has time to think about it, take a screenshot to show her friends, that kind of thing. Wouldn’t the gaslighting be so much more effective if she were to send the message piece by piece, each part disappearing as the next one appears, only to have the whole thing vanish without a trace and leaving the victim wondering if she imagined the whole thing? This is where the status bar comes in handy. Here’s how it would work:\n\n\nmessage_inline <- function() {\n  id <- cli_status(\"\")\n  cli_status_update(id, \"You found my bracelet.\"); wait()\n  cli_status_update(id, \"Now come find me.\"); wait()\n  cli_status_update(id, \"Good luck bitches.\"); wait()\n  cli_status_update(id, \"-A\"); wait()\n  cli_status_clear(id)\n}\n\n\n\nThe first line in this function uses cli_status() to create a blank message on the status bar, and returns an identifier that refers to the status bar. The next four lines all use cli_status_update() to overwrite the current state of the status bar, and then pause dramatically for two seconds. In a final act of malice, the last line in the function clears the status bar using cli_status_clear(), leaving nothing except a blank space behind. So what the victim sees is something more like this:\n\n\nmessage_inline()\n\n\n\n\n\n\n\nThis message was sent to Aria in episode 10 of season one. I’m sure it is deeply important to everyone that I mention this.\nCreating spinners\nThe ability to control the status bar opens up a world of new possibilities. Progress bars are one such possibility, but the progress package (Csárdi and FitzJohn 2019) already does this nicely, and in any case I suspect that A might be more intrigued by the possibility of spinners, since they just spin and spin and give the victim no clue about when the process is going to end. Much more appealing when the developer doesn’t know (or doesn’t want to reveal) when the wait will end. The cli package has a nice makes_spinner function that serves this purpose. Here’s an example:\n\n\nspinny <- make_spinner(\n  which = \"dots2\",\n  template = \"{spin} It's not over until I say it is.\"\n)\n\n\n\nThe which argument is used to choose how the spinner would look, and the template argument is used to define how the “spinny bit” is placed relative to the rest of the text. The spinny object includes functions to update the state of the spinner (in this case spinny$spin() would be that function), and a function to clear the spinner from the status bar. So here’s how A might define a function that uses a spinner to keep the victim in suspense…\n\n\ntheatrics <- function(which) {\n  \n  # define the spinner\n  spinny <- make_spinner(\n    which = which,\n    template = \"{spin} It's not over until I say it is.\"\n  )\n  \n  # update the spinner 100 times\n  for(i in 1:100) {\n    spinny$spin()\n    wait(.05)\n  }\n  \n  # clear the spinner from the status bar\n  spinny$finish()\n  \n  # send the final part of the message\n  cli_alert_success(\"Sleep tight while you still can, bitches. -A\")\n}\n\n\n\nHere’s what happens:\n\n\ntheatrics(\"dots2\")\n\n\n\n\n\n\n\nThis message was sent to all four of the liars in the final episode of season one. I don’t think A used a spinner though, which feels like a missed opportunity to me\nSetting which = \"dots2\" is only one possibility. There are quite a lot of different spinner types that come bundled with the cli package, and I’d imagine A would want to look around to see which one suits her needs. Personally, I’m a fan of hearts:\n\n\ntheatrics(\"hearts\")\n\n\n\n\n\n\nTo see the full list use the list_spinners() function:\n\n\nlist_spinners()\n\n\n [1] \"dots\"                \"dots2\"               \"dots3\"              \n [4] \"dots4\"               \"dots5\"               \"dots6\"              \n [7] \"dots7\"               \"dots8\"               \"dots9\"              \n[10] \"dots10\"              \"dots11\"              \"dots12\"             \n[13] \"line\"                \"line2\"               \"pipe\"               \n[16] \"simpleDots\"          \"simpleDotsScrolling\" \"star\"               \n[19] \"star2\"               \"flip\"                \"hamburger\"          \n[22] \"growVertical\"        \"growHorizontal\"      \"balloon\"            \n[25] \"balloon2\"            \"noise\"               \"bounce\"             \n[28] \"boxBounce\"           \"boxBounce2\"          \"triangle\"           \n[31] \"arc\"                 \"circle\"              \"squareCorners\"      \n[34] \"circleQuarters\"      \"circleHalves\"        \"squish\"             \n[37] \"toggle\"              \"toggle2\"             \"toggle3\"            \n[40] \"toggle4\"             \"toggle5\"             \"toggle6\"            \n[43] \"toggle7\"             \"toggle8\"             \"toggle9\"            \n[46] \"toggle10\"            \"toggle11\"            \"toggle12\"           \n[49] \"toggle13\"            \"arrow\"               \"arrow2\"             \n[52] \"arrow3\"              \"bouncingBar\"         \"bouncingBall\"       \n[55] \"smiley\"              \"monkey\"              \"hearts\"             \n[58] \"clock\"               \"earth\"               \"moon\"               \n[61] \"runner\"              \"pong\"                \"shark\"              \n[64] \"dqpb\"               \n\nShowing cli messages in R markdown\nThroughout this post I’ve relied on asciicast to display screencasts of the R console as animated SVG files, rather than what I might normally do and rely on regular R markdown code chunks to do the work. There’s a reason for this: the R console is a terminal, and its behaviour doesn’t always translate nicely to HTML. Part of the magic of the rmarkdown package (Xie, Allaire, and Grolemund 2018) is that most of the time it is able to capture terminal output and translate it seamlessly into HTML, and we mere mortal users never notice how clever this is. However, when dealing with cli output, we run into cases where this breaks down and the law of leaky abstractions comes into play: text generated at the R console does not follow the same rules as text inserted into an HTML document, and R Markdown sometimes needs a little help when transforming one to the other.\nAn important thing to remember about cli is that the text it produces is a message, so its visibility in R Markdown depends on the chunk option for messages. As long as the message option is set to TRUE, R Markdown will include them as part of the output.2 In the simplest case, R Markdown works nicely, so as long as all A wants to do is send an unformatted threat within an R Markdown document, then this works:\n\n\ncli_text(\"I'm still here bitches, and I know everything. -A\")\n\n\nI'm still here bitches, and I know everything. -A\n\nHowever, the moment A tries to use any fancy formatting, things will go haywire for her. For example, suppose she wanted to send the message above as a simple “alert” message using cli_alert(), which uses fancy symbols and colours in the output. It is at this point that the cracks in the R Markdown pipeline start to leak. In this case, the leak would result in the document failing to knit and an error message complaining about\nPCDATA invalid Char value\nIntuitively she might guess that somewhere in the R Markdown pipeline, an invalid or malformed character has been created.3 The reason this happens is that the colours and symbols used by cli, and supported in the R console, rely on ANSI escape codes, but those escape codes aren’t recognised in HTML and – apparently – they can wreak havoc when R markdown writes those characters into the HTML document. ANSI colours in R are usually generated with the help of the crayon package (Csárdi 2021b), and per the issue #24 thread that I encounter on a semi-regular basis, it can be tricky to manage the process of translating these to HTML via R Markdown.\nSolving this issue requires A to jump through a few hoops. It’s annoying I know, but no-one ever said that running an unhinged stalking campaign via text messages was easy, right? Her first task is to make sure that the R Markdown document turns on crayon support:\n\n\noptions(crayon.enabled = TRUE)\n\n\n\nThis isn’t the whole solution, however, because while that tells R Markdown to stop ignoring all the ANSI stuff, it doesn’t necessarily allow it to render ANSI sequences properly. To fix this she needs to specify the knit hooks that explicitly tell R Markdown what to do. She can do this with the help of the fansi package (Gaslam 2021), which contains an obscurely-named function sgr_to_html() that translates a subset of the ANSI control sequences to HTML, and strips out all the others. Using this, she can write an ansi_aware_handler() function that will take an input string x and return HTML output appropriate for the R Markdown context:\n\n\nansi_aware_handler <- function(x, options) {\n  paste0(\n    \"<pre class=\\\"r-output\\\"><code>\",\n    fansi::sgr_to_html(x = x, warn = FALSE, term.cap = \"256\"),\n    \"<\/code><\/pre>\"\n  )\n}\n\n\n\nFrom there, it’s relatively easy. All she needs to do is tell knitr (Xie 2021) to use this function whenever it needs to handle output. Just for good measure she might do the same for messages, errors, and warnings:\n\n\nknitr::knit_hooks$set(\n  output = ansi_aware_handler, \n  message = ansi_aware_handler, \n  warning = ansi_aware_handler,\n  error = ansi_aware_handler\n)\n\n\n\nAt long last she is done.4 Her campaign of bullying and cruelty can continue:\n\n\ncli_alert(\"I'm still here bitches, and I know everything. -A\")\n\n\n→ I'm still here bitches, and I know everything. -A\n\n\n\nThis message was sent in the pilot episode. Yes, the quotes I’ve used are all from season one: I’ve just started a rewatch of the show, so the early episodes are quite fresh in my memory!\nWriting longer messages\nUp to this point the threatening messages that A has been sending have been short, only one line long. In several cases the messages have been cleverly constructed so that the same line (the status bar) is used to display multiple pieces of text, but ultimately it’s still one line messaging. A needs to take a little care when she wants to branch out. Conceptually, a message should correspond to “one semantically meaningful bundle of information” that might be split over several lines. However, as far as R is concerned, each call to cli_text() creates a distinct message. To see how this might cause A some grief, here’s the letter that she sent to Aria’s mother announcing the infidelity of Aria’s father:\n\n\nsend_cruel_letter_piecewise <- function() {\n  cli_text('Your husband, Byron, is involved with another woman')\n  cli_text('and when I say involved I mean in a \"romantic\" way.')\n  cli_text('This is not something recent. It started before your')\n  cli_text('family went away to Iceland and from the look of')\n  cli_text('things, it may be starting up again now that you\\'re')\n  cli_text('back. I know this is hard to hear, but it is the')\n  cli_text('truth. If you don\\'t believe this about your husband,')\n  cli_text('ask your daughter. She knows all about it.')\n  cli_text('Sincerely,')\n  cli_text('A')\n}\n\nsend_cruel_letter_piecewise()\n\n\nYour husband, Byron, is involved with another woman\n\nand when I say involved I mean in a \"romantic\" way.\n\nThis is not something recent. It started before your\n\nfamily went away to Iceland and from the look of\n\nthings, it may be starting up again now that you're\n\nback. I know this is hard to hear, but it is the\n\ntruth. If you don't believe this about your husband,\n\nask your daughter. She knows all about it.\n\nSincerely,\n\nA\n\n\nThis is not an ideal implementation. What A wants to send is one message spanning 10 lines not 10 separate one-line messages, but it’s the latter that she has actually implemented here. This is where the cli() function is handy: to takes an expression as input and collects all the constituent parts into a single message. This version of the function now sends a single message:\n\n\nsend_cruel_letter_singly <- function() {\n  cli({\n    cli_text('Your husband, Byron, is involved with another woman')\n    cli_text('and when I say involved I mean in a \"romantic\" way.')\n    cli_text('This is not something recent. It started before your')\n    cli_text('family went away to Iceland and from the look of')\n    cli_text('things, it may be starting up again now that you\\'re')\n    cli_text('back. I know this is hard to hear, but it is the')\n    cli_text('truth. If you don\\'t believe this about your husband,')\n    cli_text('ask your daughter. She knows all about it.')\n    cli_text('Sincerely,')\n    cli_text('A')\n  })\n}\n\nsend_cruel_letter_singly()\n\n\nYour husband, Byron, is involved with another woman\nand when I say involved I mean in a \"romantic\" way.\nThis is not something recent. It started before your\nfamily went away to Iceland and from the look of\nthings, it may be starting up again now that you're\nback. I know this is hard to hear, but it is the\ntruth. If you don't believe this about your husband,\nask your daughter. She knows all about it.\nSincerely,\nA\n\n\n\nThe letter was sent to Ella in episode four season one. Even on a rewatch I’m finding it impossible to imagine Holly Marie Combs as anyone other than Piper from Charmed and I keep expecting “Ella” to stop time and, idk, shave off her husbands eyebrows or something?\nMuch nicer. As every would-be tormenter knows, it’s important to pay attention to the details.\nCreating structured messages\nWriting long messages when sending a threatening letter is a simple enough thing, but at some point A will likely find herself wanting to add some structure to these missives. Lists are nice. Stalkers like keeping lists, I hear. With that in mind, a nice property of cli is that it allows you to separate style from structure using an HTML-like syntax. Top level headings are specified using cli_h1(), and second level headings are produced by cli_h2(). Unordered lists are produced using cli_ul() and ordered lists by cli_ol(). This make it easy to write structured messages to the R console:\n\n\ncli({\n  cli_h1(\"Characters\")\n  cli_h2(\"The Liars\")\n  cli_ul(c(\n    \"Alison DiLaurentis\",\n    \"Spencer Hastings\",\n    \"Aria Montgomery\",\n    \"Hanna Marin\",\n    \"Emily Fields\"\n  ))\n  cli_h2(\"The A-Team\")\n  cli_ul(c(\n    \"Mona Vanderwaal\",\n    \"Lucas Gottesman\",\n    \"Melissa Hastings\"\n  ))\n})\n\n\n\n── Characters ────────────────────────────────────────────────────────\n\n── The Liars ──\n\n• Alison DiLaurentis\n• Spencer Hastings\n• Aria Montgomery\n• Hanna Marin\n• Emily Fields\n\n── The A-Team ──\n\n• Mona Vanderwaal\n• Lucas Gottesman\n• Melissa Hastings\n\n\nBetter yet, the cli package has a whole swathe of other utilities that follow this same HTML-like naming scheme, making it possible to send elaborate and disturbing messages in so many different ways.\nEpilogue\nThere is a lot more to the cli package that I haven’t talked about in this post. I’ve not talked about how to modify the themes, how to create custom cli “apps” that use different themes or send output to different connections. I’ve not talked about how to use conditional logic within a cli call, displaying different messages depending on whether a process succeeds or fails. Those will have to remain secret for now, because this post is quite long enough already and quite frankly I’m still learning myself. Besides, these powers would no doubt would be put to terrible purposes in an R-themed Pretty Little Liars spinoff show, and I’m not entirely sure that all secrets need sharing…\n\n\ncli(\n  cli_blockquote(\n    quote = \"Friends share secrets, that's what keeps us close\",\n    citation = \"Alison\"\n  )\n)\n\n\n\n    “Friends share secrets, that's what keeps us close”\n    — Alison\n\n\n\n\nLast updated\n\n\n2021-09-13 16:35:48 AEST\n\n\nDetails\n\n\n\nsource code\n, \nR environment\n\n\n\n\n\n\n\n\n\n\n\nCsárdi, Gábor. 2021a. Cli: Helpers for Developing Command Line Interfaces. https://CRAN.R-project.org/package=cli.\n\n\n———. 2021b. Crayon: Colored Terminal Output. https://CRAN.R-project.org/package=crayon.\n\n\nCsárdi, Gábor, and Rich FitzJohn. 2019. Progress: Terminal Progress Bars. https://CRAN.R-project.org/package=progress.\n\n\nCsárdi, Gábor, Romain Francois, Mario Nebl, and Marcin Kulik. 2019. Asciicast: Create ’Ascii’ Screen Casts from r Scripts. https://CRAN.R-project.org/package=asciicast.\n\n\nGaslam, Brodie. 2021. Fansi: ANSI Control Sequence Aware String Functions. https://CRAN.R-project.org/package=fansi.\n\n\nXie, Yihui. 2021. Knitr: A General-Purpose Package for Dynamic Report Generation in r. https://yihui.org/knitr/.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. R Markdown: The Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown.\n\n\nYes, it does disappear in this screencast, but that’s just the screencast. If it were the R console it would stay on screen the whole time.↩︎\nSomewhat counterintuitively, although cli emits messages that can be suppressed by suppressMessages(), they don’t behave precisely the same as the messages produced by message(). The default handler for base R messages sends the output to the stderr() connection and so they are often shown as the dreaded “red text” that users learn to fear. To avoid this, the default behaviour in cli sends messages to the stdout() connection, thereby avoiding this issue. However, cli does allow you to control this behaviour: see the start_app() and stop_app() functions for more information.↩︎\nAs an aside, if you’re running a site with an RSS feed it may also write malformed characters into the index.xml file as well as any generated .html file. When I encountered this problem I found that even when I “fixed” my .Rmd file the document wouldn’t re-knit, because of the problems with the xml file. Eventually I realised that I could solve the problem by deleting the index.xml file for the RSS feed and then knitting again. Sigh↩︎\nNote that there is also the fansi::set_knit_hooks() function which will set the hooks in a more user-friendly way. I don’t think there’s any reason not to use it: the only reason I didn’t is that I found it convenient to write things from scratch here so that I understood what was happening.↩︎\n",
    "preview": "posts/2021-04-18_pretty-little-clis/pretty-little-clis.jpg",
    "last_modified": "2021-09-13T16:35:49+10:00",
    "input_file": "index.knit.md"
  },
  {
    "path": "posts/2021-04-05_welcome/",
    "title": "Welcome to the jungle",
    "description": "I have reluctantly decided to create a new blog. Some thoughts on \nwhat I hope to achieve, having tried my hand at blogging so very many times \nbefore",
    "author": [
      {
        "name": "Danielle Navarro",
        "url": "https://djnavarro.net"
      }
    ],
    "date": "2021-04-05",
    "categories": [],
    "contents": "\n\n\nI’ve decided the time has come to restart my blog. I’ve tried blogging many times before with mixed success, and this time around I’d like to avoid the mistakes of the past. I’ve set up this blog with a few principles in mind:\nSimplicity. One mistake I’ve often made is to create blogs using the fanciest tools I could find. For example, I’ve previously used Hugo based packages like blogdown and hugodown, and much as I love those tools (and use them on other sites) I want this blog to be as low-maintenance as possible. To that end I’m using distill for R markdown, and I’m keeping the default settings in most respects.\nEncapsulation. There was a time when I really liked the idea of having my blog integrated nicely with my homepage (djnavarro.net). I’ve become less keen on this because the aesthetic and technical demands of a blog aren’t always aligned with the needs of my homepage. This time I’ve set it up so that the blog.djnavarro.net subdomain corresponds to a different repository from my homepage. I’m hoping this will make blogging simpler from a technical standpoint.\nFocus. Another mistake I have made in the past is letting blogs “sprawl”, mixing personal essays with technical posts. My intention with this blog is to write technical posts only, mostly on R and data science. I’ve moved my personal writing to essays.djnavarro.net and my artwork to art.djnavarro.net. My hope is that this will make blogging easier from an emotional standpoint.\nReproducibility. A frustration I’ve had with my previous blogs is that my posts were not particularly reproducible. Source code was often missing, information about the R session was not provided, and so on. This time, I’ve set up the blog so that there is a “details” section at the bottom of each post containing links to the source code, the R session information, and a lockfile generated using renv::snapshot(). (Edit: from 2021-08-23 I’ve extended this approach so that every post actually uses the previously stored R environment)\nAt this stage I’m not entirely certain how I’ll use the blog. There are a lot of possibilities, and I have some thoughts on which ones I’d like to explore. A self-contained blog such as this seems nicely suited to teaching materials. An obvious example would be to write blog posts to accompany the data science slides and youtube videos I’ve been making. The lack of written material to go with those talks has bothered me for some time. Another possibility might be to write tutorials on generative art. I use my art website to post the art itself, but the site functions as a gallery rather than a classroom. I get a lot of people asking questions about how I make my art, and this blog might be a good place to provide answers. Those aren’t the only possibilities, of course, but they are appealing ones.\nNot sure how this will go, but fingers crossed!\n\n\nLast updated\n\n\n2021-09-13 16:34:39 AEST\n\n\nDetails\n\n\n\nsource code\n, \nR environment\n\n\n\n\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-04-05_welcome/welcome.jpg",
    "last_modified": "2021-09-13T16:34:40+10:00",
    "input_file": "index.knit.md"
  }
]
