---
title: "Binding Apache Arrow to R"
description:
  Neque porro quisquam est qui dolorem ipsum quia dolor sit amet, 
  consectetur, adipisci velit # <---- UPDATE ME
author:
  - first_name: "Danielle"
    last_name: "Navarro"
    url: https://djnavarro.net
    affiliation: Voltron Data
    affiliation_url: https://voltrondata.com
    orcid_id: 0000-0001-7648-6578
date: 2022-01-18
preview: img/muhammad-haikal-sjukri--RMBf_xSf2U-unsplash.jpg
creative_commons: CC BY
citation_url: https://blog.djnavarro.net/binding-arrow-to-r
repository_url: https://github.com/djnavarro/distill-blog/
output:
  distill::distill_article:
    self_contained: false
    toc: true
params:
  slug: binding-arrow-to-r
  date: 2022-01-18
  repo: djnavarro/distill-blog
  site: https://blog.djnavarro.net/
---

<!----

checklist:
  - check the "update me" messages in YAML above
  - initialise the _renv folder with refinery::renv_new("name of post folder")
  - populate the lockfile with refinery::renv_snapshot("name of post folder")
  - update the _renv folder from snapshot with refinery::restore("name of post folder")

---->


<!--------------- setup post ----------------->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = TRUE)
refinery::renv_load(paste(params$date, params$slug, sep = "_"))

# save the built-in output hook
hook_output <- knitr::knit_hooks$get("output")

# set a new output hook to truncate text output
knitr::knit_hooks$set(output = function(x, options) {
  if (!is.null(n <- options$out.lines)) {
    x <- xfun::split_lines(x)
    if (length(x) > n) {
      # truncate the output
      x <- c(head(x, n), "....\n")
    }
    x <- paste(x, collapse = "\n")
  }
  hook_output(x, options)
})

# ensure that renv detects ggplot2 dependency
ggplot2::element_blank()
```


<!--------------- post ----------------->

So I have a new job. 

In my previous job as an academic, a large part of my work -- my favourite part, if I'm honest -- involved creating open access resources to help people use modern open source tools for data analysis. In my totally different role in developer relations at Voltron Data, a large part of my work involves, um ... *[checks job description]* ... creating open access resources to help people use modern open source tools for data analysis. Well okay then! 

I'd better get on that, I suppose?

I've been in my current role for a little over a week, and today my [first contribution](https://github.com/apache/arrow/pull/12173/) to Apache Arrow was merged. It was very modest contribution: I wrote some code that determines whether any given year is a leap year. It precisely mirrors the behaviour of the `leap_year()` function in the **lubridate** package, except that it can be applied to Arrow data and it will behave itself when used in the context of a **dplyr** pipeline (more on that later). The code itself is not complicated, but it relies on a little magic and a deeper understanding of Arrow than I possessed two weeks ago.  

<aside>Throughout this post I'll use boldface to refer to specific R packages like **dplyr** or C++ libraries like **libarrow**</aside>

This post is the story of how I learned this sorcery.

```{r}
#| echo = FALSE,
#| fig.align = "center",
#| fig.cap = "Two key moments in \"The Magicians\" when Julia Wicker discovers she can do magic, defying the expectations of others. One moment occurs at the start of Season 1 as a novice, after she had been told she failed the magic exams at Brakebills University; another moment occurs at the end of Season 2 after all magic has supposedly been turned off by the Old Gods or something. The parallel between the two moments is striking. Oh and Quentin Coldwater is in both scenes too I guess. Whatevs. Image via [giphy](https://giphy.com/gifs/syfy-magic-julia-xUA7b94cNgJ4qoi532), copyright [syfy](https://www.syfy.com)"
knitr::include_graphics("https://media.giphy.com/media/xUA7b94cNgJ4qoi532/giphy-downsized-large.gif")
```

<aside><br>Yes I have been binge watching [*The Magicians*](https://en.wikipedia.org/wiki/The_Magicians_(American_TV_series)) lately. My preemptive apologies to everyone for the gif spam.</aside>

## Why am I writing this?

> The danger of sublimated trauma is a major theme in our story <br>
> &nbsp; &nbsp; -- The Great God Ember (The Magicians: Season 2, Episode 3)

It might seem peculiar that I'm writing such a long post about such a tiny contribution to an open source project. After all, it doesn't actually take a lot of work to figure out how to detect leap years. You can do it in one line of R code:

```{r, eval=FALSE}
(year %% 4 == 0) & ((year %% 100 != 0) | (year %% 400 == 0))
```

This is a logical expression corresponding to the following rules. If the `year` is divisible by 4 then it is a leap year (e.g., 1996 was a leap year). But there's an exception: if `year` is divisible by 100 then it isn't a leap year (e.g., 1900 wasn't a leap year). But there's also an exception to the exception: if `year` is divisible by 400 then it is a leap year (e.g., 2000 was a leap year). Yes, the process of mapping the verbally stated rules onto a logical expression is kind of annoying, but it's not conceptually difficult or unusual. There is no magic in leap year calculation, no mystery that needs unpacking and explaining.

<aside>All this assumes years are counted using the [Gregorian calendar](https://en.wikipedia.org/wiki/Gregorian_calendar). There are, of course, [other calendars](https://en.wikipedia.org/wiki/List_of_calendars)</aside>

The magic comes in when you start thinking about what the **arrow** package actually does. It lets you write perfectly ordinary R code for data manipulation that returns perfectly ordinary R data structures, even though the data have never been loaded into R and all the computation is performed externally using Apache Arrow. The code you write with **arrow** looks and feels like regular R code, but almost none of the work is being done by R. This *is* deep magic, and it is this magic that needs to be demystified.

I have three reasons for wanting to unpack and explain this magic. 

The first reason is personal: I've been a professional educator for over 15 years and it has become habit. The moment I learn a new thing my first impulse is to work out how to explain it to someone else. The second reasons is professional: I work for Voltron Data now, and part of my job is to make an educational contribution to the open source Apache Arrow project. Arrow is a pretty cool project, but there's very little value in magnificent software if you don't help people learn how to take advantage of it! The third reason is ethical: a readable tutorial/explanation lowers barriers to entry. I mean, let's be honest: the only reason I was able to work up the courage to contribute to Apache Arrow is that I work for a company that is deeply invested in open source software and in the Arrow project specifically. I had colleagues and friends I could ask for advice. If I failed I knew they would be there to help me. I had a safety net. 

The last of these is important from an equity and inclusion point of view. Not everyone has the safety net that I have, and in a former lifetime I've been on the other side. I've been the person with no support, nobody to ask for help, and I've run afoul of capricious gatekeeping in the open source world. It is a deeply unpleasant experience, and one I would not wish upon anyone else. The quote from Ember about the danger of sublimated trauma is relevant here: if we want healthy user communities it is our *obligation* on the inside to provide safe environments and delightful experiences. Our job is to find and remove barriers to entry. We want to provide that "safety net" that ensures that even if you fall (because we all fall sometimes), you don't get hurt. Failing at something is often a learning experience; trauma, on the other hand, is not.

<aside>Everyone deserves a [safety net](https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/rstats-artwork/code_hero_rstats.png) when first learning to walk the tightropes. It's not a luxury, it's a necessity</aside>

So yeah. I'm not usually a person prone to earnestness but this is something that matters to me. It's time for me to pay it forward, so to speak. I'd like to take what I've learned and make that knowledge more widely accessible. 

Before diving in, I should say something about the "assumed knowledge" for this post. I'm assuming that the reader is comfortable in R, knows how to use **dplyr** for data manipulation, and has some vague familiarity with what Apache Arrow is all about. If you need a refresher on R and **dplyr**, ["R for data science"](https://r4ds.had.co.nz/) is always a fabulous resource! On the Arrow side, I'll try my best to provide all the context you need in this post, but if you want a little more background on Arrow I wrote a post on ["Getting started with Apache Arrow"](https://blog.djnavarro.net/starting-apache-arrow-in-r) that starts at the very beginning and discusses a lot of the basics. 


```{r}
#| echo = FALSE,
#| fig.align = "center",
#| fig.cap = "The Great God Ember. Capricious, chaotic, and utterly unreliable unless what you're looking for is a whimsical death. Pretty much the opposite of what we'd hope for in a healthy open source community really! He is, however, a very entertaining character. Image via [giphy](https://giphy.com/gifs/syfy-the-magicians-fillory-26gswa3eMvprpfjSE), copyright [syfy](https://www.syfy.com)"
knitr::include_graphics("https://media.giphy.com/media/26gswa3eMvprpfjSE/giphy.gif")
```



## Primer: What is Arrow?





## The Arrow C++ compute kernel

A fundamental thing to understand about the **arrow** package in R is that it doesn't implement the Apache Arrow standard directly. In fact, it tries very hard not to do any of the heavy lifting itself. There's a C++ library that does that in a super efficient way, and the job of the R package is to supply bindings that allow the R user to interact with that library using a familiar interface. The C++ library is called **libarrow**. Although the long term goal is to make the integration so seamless that you can use the **arrow** R package without ever *needing* to understand the C++ library, my experience has been that most people *want* to know something about what's happening under the hood. It can be unsettling to find yourself programming with tools you don't quite understand, so I'll dig a little deeper in this post.

Let's start with the C++ library. The role of **libarrow** is to do all the heavy computational work. It implements all the Arrow standards for representing tabular data in memory, provides support for the Apache "Inter-Process Communication" (IPC) protocol that lets you efficiently transfer data from one application to another, and supplies a *compute kernel* that allows you to do some data wrangling when your data are represented as an Arrow table. It is, fundamentally, the engine that makes everything work.

What about the R package? The role of **arrow** is to expose the functionality of **libarrow** to the R user, to make that functionality feel "natural" in R, and to make it easier for R users to write Arrow code that is smoothly interoperable with Arrow code written in other languages (e.g., Python). In order to give you the flexibility you need, the **arrow** package allows you to interact with **libarrow** at three different levels of abstraction:

- There's a heavily abstracted interface that uses [the dplyr bindings supplied by arrow](#using-dplyr-bindings). This version strives to make **libarrow** almost completely invisible, hidden behind an interface that uses familiar R function names.
- There's a lightly abstracted interface you can access [using the `arrow_*()` functions](#using-arrow-functions). This version exposes the **libarrow** functions without attempting to exactly mirror any particular R functions, but providing some convenient "syntactic sugar" that allows you to pass R objects.
- Finally, there's a minimally abstracted interface [using `call_function()`](#using-call-function). This version provides a bare bones interface, without any of the syntactic sugar.

In the rest of this section I'll talk about these three levels of abstraction. Let's load the packages we're going to need for this post and dive right in!

```{r}
library(tibble)
library(dplyr)
library(lubridate)
library(arrow)
```

```{r}
#| echo = FALSE,
#| fig.align = "center",
#| fig.cap = "Penny Adiyodi in the Neitherlands, diving head first into a fountain taking him to a new and magical world. Image via [giphy](https://giphy.com/gifs/syfy-penny-alice-26gscWcSEXuJH91tK), copyright [syfy](https://www.syfy.com)"
knitr::include_graphics("https://media.giphy.com/media/26gscWcSEXuJH91tK/giphy.gif")
```


### Using the **dplyr** bindings in **arrow** {#using-dplyr-bindings}

When I wrote my [Getting started with Apache Arrow](https://blog.djnavarro.net/starting-apache-arrow-in-r) post, I concluded with an illustration of how you can write **dplyr** code that will work smoothly in R even when the data themselves are stored in Arrow. Here's a little recap of how that works, using the `economics` data from the **ggplot2** package. Here's what that data set looks like:

```{r}
data(economics, package = "ggplot2")
economics
```

Let's suppose I wanted to calculate the average unemployment rate for every year in the data. The **dplyr** package provides me with the tools I need to do this, using functions like `mutate()` to create new variables, `group_by()` to specify grouping variables, and `summarise()` to aggregate data within group:

```{r}
economics %>% 
  mutate(year = year(date)) %>% 
  group_by(year) %>% 
  summarise(uempmed = mean(uempmed))
```

All of these computations take place within R. The `economics` data set is stored in R, and all the calculations are done using this data structure. What can we do when the data are stored in Arrow? Well, first I'll create an `arrownomics` variable using the `arrow_table()` function:

```{r}
arrownomics <- arrow_table(economics)
arrownomics
```

When I do this, two things happen. First, a data set is created outside of R (in memory allocated to Arrow) -- all of the computations will be done on that data set. Second, the `arrownomics` variable is created inside R, which consists of a pointer to the actual data along with some handy metadata. The **arrow** package allows you to design **dplyr** pipelines using only this pointer object:

```{r}
arrownomics %>% 
  mutate(year = year(date)) %>% 
  group_by(year) %>% 
  summarise(uempmed = mean(uempmed))
```

When the input is `arrownomics`, the effect of the **dplyr** code is construct a query that can be passed to **libarrow** to be evaluated. This works because the **arrow** package supplies methods for `mutate()`, `group_by()`, and `summarise()` that are called whenever the input data is and Arrow Table. 

It's important to realise that at this point, no actual computations have been performed on the Arrow data. If you want the query to be evaluated using the data, you need to use the `compute()` or `collect()` functions at the end of the pipeline. These two functions behave slightly differently. The `compute()` function runs the query, but leaves the resulting data inside Arrow. 

```{r}
arrownomics %>% 
  mutate(year = year(date)) %>% 
  group_by(year) %>% 
  summarise(uempmed = mean(uempmed)) %>% 
  compute()
```

This can be useful when you're creating an intermediate data set that you want to reuse in Arrow later. If, on the other hand, you want the output to be pulled into R so that you can do R computation with it, use the `collect()` function:

```{r}
arrownomics %>% 
  mutate(year = year(date)) %>% 
  group_by(year) %>% 
  summarise(uempmed = mean(uempmed)) %>% 
  collect()
```

The nice thing for R users is that all of this feels like regular R code. Although **libarrow** is doing all the serious computation -- none of the real work is being done within R -- but the user really doesn't need to worry too much about that. The **dplyr** interface provided by the **arrow** package works seamlessly and invisibly.

In our ideal world, the **dplyr** interface is all you would ever need to use. Internally, the **arrow** package would intercept all the R function calls you make, and replace them with an equivalent function that performs exactly the same computation using **libarrow**. You the user would never need to think about what's happening under the hood.

Real life, however, is filled with [leaky abstractions](https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/), and the **arrow** package is no exception. The current version of the package (v6.0.1) doesn't mirror all the functionality of **dplyr** and the support for other tidyverse packages like **lubridate** and **stringr** is very much a work in progress! For example, the current release doesn't support the `leap_year()` function in **lubridate** -- not surprising, since that's exactly the thing I was trying to fix in my first contribution -- and whenever it encounters a function it doesn't know how to handle, **arrow** will throw a warning, pull the data into R and try to complete the query using native R code. Here's what that looks like:

```{r}
arrownomics %>% 
  mutate(year = year(date)) %>% 
  group_by(year) %>% 
  summarise(
    uempmed = mean(uempmed),
    leap = leap_year(year)
  ) %>% 
  collect()
```

In this case, the warning is telling you that the computations weren't actually performed in Arrow: realising that it doesn't know how to interpret `leap_year()`, the **arrow** package has tried to "fail gracefully" and pulled everything back into R where the `leap_year()` function *is* defined.

```{r}
#| echo = FALSE,
#| fig.align = "center",
#| fig.cap = "Quentin from timeline 40 talking to Alice from timeline 23. Communication across incommensurate universes is difficult. In the show it requires a Tesla Flexion. In Arrow, we use dplyr bindings. Image via [giphy](https://giphy.com/gifs/syfy-alice-love-you-xUPGcJ8PkgoCQFMjHW), copyright [syfy](https://www.syfy.com)"
knitr::include_graphics("https://media.giphy.com/media/xUPGcJ8PkgoCQFMjHW/giphy.gif")
```


### Using the `arrow_*()` functions in **dplyr** code {#using-arrow-functions}

Okay, let's dig a little deeper. 

In the last section I talked about the **dplyr** bindings that **arrow** provides, which are designed to mimic their native R equivalents as seamlessly as possible. These bindings work by rewriting the R functions that they mimic using only the C++ compute functions supplied by **libarrow**. That's the way you'd usually interact with Arrow in R, but you can access those compute functions more directly. To see what compute functions are exposed by the C++ **libarrow** library, you can call `list_compute_functions()` from R:

```{r, out.lines = 10}
list_compute_functions()
```

The actual output continues for quite a while: there are currently `r length(list_compute_functions())` compute functions, most of which are low level functions needed to perform basic computational operations. 

There are two different ways you can call these compute functions yourself, one that provides a little [syntactic sugar](https://en.wikipedia.org/wiki/Syntactic_sugar) to make your life a little easier, and another that calls the functions pretty directly. I'll talk about the first of these in this section.  

Let's imagine you're writing **dplyr** code to work with datetime data in a Table object like `arrownomics`. If you were working with native R data like `economics`, you can do something like this:

```{r}
economics %>% 
  mutate(days = date - as.Date("1967-01-01"))
```

Here I've created a new `days` column that counts the number of days that have elapsed between the `date` variable and January 1st, 1967. There are a lot of data analysis situations in which you might want to do exactly this, but right now you can't actually do this using the **arrow** dplyr bindings because temporal arithmetic is a work in progress (I'm making small contributions to that myself, actually!). In the not-too-distant future users should be able to expect code like this to work seamlessly, but right now it doesn't. If you try it right now, you get this error:

```{r, error=TRUE}
arrownomics %>% 
  mutate(days = date - as.Date("1967-01-01")) %>% 
  collect()
```

Right now, there are no general purpose arithmetic operations in **arrow** that allow you to subtract one date from another. However, because I chose this example rather carefully to find an edge case where the R package is missing some **libarrow** functionality, it turns out there is actually a `days_between()` function in **libarrow** that we could use to solve this problem, and it's not too hard to use it. If you want to call one of the **libarrow** functions inside your **dplyr** pipeline, all you have to do is add an `arrow_` prefix to the function name. For example, the C++ `days_between()` function becomes `arrow_days_between()` when called within the **arrow** **dplyr** pipeline:

```{r}
arrownomics %>% 
  mutate(days = arrow_days_between(as.Date("1967-01-01"), date)) %>% 
  collect()
```

Notice there's no warning message here. That's because the computations were done in Arrow and the data have not been pulled into R. 


```{r}
#| echo = FALSE,
#| fig.align = "center",
#| fig.cap = "Okay fine, there's no connection between slightly-evil-Julia burning down the talking trees and calling libarrow functions in dplyr pipes. I just love this scene and secretly wish I was her. Image via [giphy](https://giphy.com/gifs/syfy-l0IydgNESZjrALWqA), copyright [syfy](https://www.syfy.com)"
knitr::include_graphics("https://media.giphy.com/media/l0IydgNESZjrALWqA/giphy.gif")
```


### Accessing **libarrow** with `call_function()` {#using-call-function}

Okay, here's a puzzle:

```{r, error=TRUE}
date1 <- as.Date("1967-01-01")
date2 <- as.Date("2022-01-18")

arrow_days_between(date1, date2)
```

There is no R function called `arrow_days_between()`, yet I was somehow able to "call" it in the previous example? The answer here is that the **arrow** package is doing a bit of metaprogramming magic. What's actually happening here is that when you use it in the **dplyr** context, **arrow** will intercepts the call to `arrow_days_between()` and quietly pass it to **libarrow** for you. 

If you *really* want to do it directly, you can use `call_function()` from the **arrow** package. This provides you with direct access to a **libarrow** function. It won't take care of the low-level communication between R and Arrow though: the **libarrow** functions expect to receive Arrow-native data structures as input. That's the price you pay for low-level access: you have to do all the low-level work!

```{r}
arrow_date1 <- Scalar$create(date1)
arrow_date2 <- Scalar$create(date2)

arrow_date1
```


Now you can do this:

```{r}
call_function("days_between", arrow_date1, arrow_date2)
```


```{r}
#| echo = FALSE,
#| fig.align = "center",
#| fig.cap = "Kady was an under-used character. Image via [giphy](https://giphy.com/gifs/syfy-the-magicians-kady-xUA7b4focaBB2CVSBq), copyright [syfy](https://www.syfy.com)"
knitr::include_graphics("https://media.giphy.com/media/xUA7b4focaBB2CVSBq/giphy.gif")
```


## Writing functions that play nicely with arrow pipes

```{r}
arrowish_leap_year <- function(date) {
   year <- Expression$create("year", date)
  (year %% 4 == 0) & ((year %% 100 != 0) | (year %% 400 == 0))
}
```

Trying to use lubridate fails:

```{r}
arrownomics %>% 
  mutate(leap = leap_year(date)) %>% 
  collect()
```

Using our function works:

```{r}
arrownomics %>% 
  mutate(leap = arrowish_leap_year(date)) %>% 
  collect()
```



```{r}
#| echo = FALSE,
#| fig.align = "center",
#| fig.cap = "Eliot and Margo applaud your success. They are the best characters, and you are also the best because you have made it to the end of a long and strange blog post. Image via [giphy](https://giphy.com/gifs/syfy-bravo-the-magicians-l2Sq18e02qsxjKfBK), copyright [syfy](https://www.syfy.com)"
knitr::include_graphics("https://media.giphy.com/media/l2Sq18e02qsxjKfBK/giphy.gif")
```



## Epilogue: Where's the rest of the owl?

The story I've told in this post is a little incomplete. I've shown you how to write a function like `arrowish_leap_year()` that can slot into a **dplyr** pipeline and operate on an Arrow data structure. What I haven't explained is how the **arrow** package knows to use `arrowish_leap_year()` instead of `lubridate::leap_year()`. Internal to the **arrow** package is a line of code that is (essentially) equivalent to this:

```{r, eval=FALSE}
register_binding("leap_year", arrowish_leap_year)
```

I haven't said anything about the precise workings of `register_binding()`, in part because that's one of the mysteries I'm currently unpacking while I dig into the code base.

But that's not the only thing I've left unsaid. There's a lot of practical details I've not mentioned. I haven't talked about unit tests, for example. I haven't talked about the process of getting my code merged into the Arrow repository. I'll talk more about some of these in the follow up post on ["My first contribution to Apache Arrow"](https://blog.djnavarro.net/contributing-to-arrow).

<!--------------- appendices ----------------->

```{r, echo=FALSE}
refinery::insert_appendix(
  repo_spec = params$repo, 
  name = paste(params$date, params$slug, sep = "_")
)
```


<!--------------- miscellanea ----------------->

```{r redirect, echo=FALSE}
refinery::insert_netlify_redirect(
  slug = params$slug, 
  date = params$date
)
```




